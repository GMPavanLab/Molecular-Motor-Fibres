{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "import sys, os\n",
    "# --- bring in the styler\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "from md_styler import MDStyler\n",
    "sty = MDStyler().apply()\n",
    "NMOLS = 200\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 experiments: ['motor2m_frac-0', 'motor2m_frac-10', 'motor2m_frac2-0', 'motor2m_frac2-10', 'motor2m_frac2-90', 'motor2m_frac3-0', 'motor2m_frac3-10', 'motor2m_frac3-90', 'motor2m_frac4-90', 'motor2m_squeeze10_frac-0', 'motor2m_squeeze10_frac-10', 'motor2m_squeeze10_frac-50', 'motor2m_squeeze10_frac-90', 'motor2m_squeeze10_frac2-50', 'motor2m_squeeze12_frac-0_2', 'motor2m_squeeze12_frac-0_3', 'motor2m_squeeze14_frac-0_2', 'rotate1', 'test_nr2', 'test_nr3']\n",
      "Found 11 parameters: ['RG', 'box-z', 'g-r', 'radius', 'sasa', 'torsion', 'torsion-alpha', 'torsion-phi', 'torsion-theta', 'voronota-area', 'voronota-volume']\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('../data')\n",
    "all_files = glob.glob(str(data_path / '*.csv'))\n",
    "experiment_names = set()\n",
    "parameter_names = set()\n",
    "\n",
    "for file in all_files:\n",
    "    # Extract experiment name and parameter name from filename\n",
    "    filename = os.path.basename(file)\n",
    "    # Find the position of the last underscore\n",
    "    last_underscore_pos = filename.rfind('_')\n",
    "    if last_underscore_pos > 0:\n",
    "        # Extract experiment name (everything before last underscore)\n",
    "        exp_name = filename[:last_underscore_pos]\n",
    "        #print(filename, exp_name, last_underscore_pos)\n",
    "        # Extract parameter name (between last underscore and .csv)\n",
    "        param_name = filename[last_underscore_pos+1:].replace('.csv', '')\n",
    "        \n",
    "        experiment_names.add(exp_name)\n",
    "        parameter_names.add(param_name)\n",
    "\n",
    "print(f\"Found {len(experiment_names)} experiments: {sorted(experiment_names)}\")\n",
    "print(f\"Found {len(parameter_names)} parameters: {sorted(parameter_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot radius over time for each experiment\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for exp_name in sorted(experiment_names):\n",
    "    try:\n",
    "        # Load radius data\n",
    "        radius_file = data_path / f\"{exp_name}_radius.csv\"\n",
    "        if not radius_file.exists():\n",
    "            print(f\"No radius data for {exp_name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(radius_file)\n",
    "        \n",
    "        # Assuming first column is time and second is radius\n",
    "        time_col = df.columns[0]\n",
    "        radius_col = df.columns[1]\n",
    "        print(exp_name, df[radius_col][0])\n",
    "        \n",
    "        plt.plot(df[time_col], df[radius_col], label=exp_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {exp_name}: {e}\")\n",
    "\n",
    "plt.xlabel('Time (ps)')\n",
    "plt.ylabel('Radius (Å)')\n",
    "plt.title('Radius over time for all experiments')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which to exclude\n",
    "\n",
    "'motor2m_frac-0' seems to be from other experiment and has some weird molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_to_exclude = ['motor2m_frac-0', 'motor2m_frac2-0', 'rotate1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 17 experiments: ['motor2m_frac-10', 'motor2m_frac2-10', 'motor2m_frac2-90', 'motor2m_frac3-0', 'motor2m_frac3-10', 'motor2m_frac3-90', 'motor2m_frac4-90', 'motor2m_squeeze10_frac-0', 'motor2m_squeeze10_frac-10', 'motor2m_squeeze10_frac-50', 'motor2m_squeeze10_frac-90', 'motor2m_squeeze10_frac2-50', 'motor2m_squeeze12_frac-0_2', 'motor2m_squeeze12_frac-0_3', 'motor2m_squeeze14_frac-0_2', 'test_nr2', 'test_nr3']\n",
      "Warning: Could not determine ratio for motor2m_squeeze10_frac2-50\n",
      "Experiment ratios (fraction of molecule B):\n",
      "  motor2m_frac-10: 10\n",
      "  motor2m_frac2-10: 10\n",
      "  motor2m_frac2-90: 90\n",
      "  motor2m_frac3-0: 0\n",
      "  motor2m_frac3-10: 10\n",
      "  motor2m_frac3-90: 90\n",
      "  motor2m_frac4-90: 90\n",
      "  motor2m_squeeze10_frac-0: 0\n",
      "  motor2m_squeeze10_frac-10: 10\n",
      "  motor2m_squeeze10_frac-50: 90\n",
      "  motor2m_squeeze10_frac-90: 90\n",
      "  motor2m_squeeze12_frac-0_2: 0\n",
      "  motor2m_squeeze12_frac-0_3: 0\n",
      "  motor2m_squeeze14_frac-0_2: 0\n",
      "  test_nr2: 0\n",
      "  test_nr3: 0\n",
      "  motor2m_frac-10: 9\n",
      "  motor2m_frac2-10: 9\n",
      "  motor2m_frac2-90: 9\n",
      "  motor2m_frac3-0: 9\n",
      "  motor2m_frac3-10: 9\n",
      "  motor2m_frac3-90: 9\n",
      "  motor2m_frac4-90: 9\n",
      "  motor2m_squeeze10_frac-0: 12\n",
      "  motor2m_squeeze10_frac-10: 12\n",
      "  motor2m_squeeze10_frac-50: 12\n",
      "  motor2m_squeeze10_frac-90: 12\n",
      "  motor2m_squeeze10_frac2-50: 12\n",
      "  motor2m_squeeze12_frac-0_2: 9\n",
      "  motor2m_squeeze12_frac-0_3: 9\n",
      "  motor2m_squeeze14_frac-0_2: 9\n",
      "  test_nr2: 15\n",
      "  test_nr3: 15\n"
     ]
    }
   ],
   "source": [
    "valid_experiments = sorted(list(experiment_names - set(experiments_to_exclude)))\n",
    "print(f\"Analyzing {len(valid_experiments)} experiments: {valid_experiments}\")\n",
    "\n",
    "# Define utility function to get experiment ratio (molecule A vs B)\n",
    "def get_experiment_squeeze(exp_name, data_path=Path('../data')):\n",
    "    \"\"\"\n",
    "    Calculate ratio of molecule B (resid 1,2) vs molecule A (resid 3,4) for an experiment\n",
    "    Returns the ratio as a float between 0 and 1 (fraction of molecule B)\n",
    "    \"\"\"\n",
    "    # Try to find any local parameter file for this experiment\n",
    "    z_file = data_path / f\"{exp_name}_box-z.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(z_file)\n",
    "        start= df.iloc[0,1]\n",
    "        if start < 100:\n",
    "            return 15\n",
    "        if start < 115:\n",
    "            return 12\n",
    "        return 9\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_experiment_ratio(exp_name, data_path=Path('../data')):\n",
    "    \"\"\"\n",
    "    Calculate ratio of molecule B (resid 1,2) vs molecule A (resid 3,4) for an experiment\n",
    "    Returns the ratio as a float between 0 and 1 (fraction of molecule B)\n",
    "    \"\"\"\n",
    "    # Try to find any local parameter file for this experiment\n",
    "    local_files = glob.glob(str(data_path / f\"{exp_name}_RG.csv\"))\n",
    "    \n",
    "    for file in local_files:\n",
    "        df = pd.read_csv(file)\n",
    "        if 'resid' in df.columns:  # Check if it's a local parameter file\n",
    "            resids = df['resid']\n",
    "            # Count molecules of type A (resid 1,2) and type B (resid 3,4)\n",
    "            count_A = sum(1 for r in resids if r in [1, 2])\n",
    "            count_B = sum(1 for r in resids if r in [3, 4])\n",
    "            total = count_A + count_B\n",
    "            \n",
    "            if total > 0:\n",
    "                return int(count_B*100/total)\n",
    "    \n",
    "    print(f\"Warning: Could not determine ratio for {exp_name}\")\n",
    "    return None\n",
    "\n",
    "# Get ratio for each experiment\n",
    "experiment_ratios = {exp: get_experiment_ratio(exp) for exp in valid_experiments}\n",
    "experiment_squeeze = {exp: get_experiment_squeeze(exp) for exp in valid_experiments}\n",
    "print(\"Experiment ratios (fraction of molecule B):\")\n",
    "for exp, ratio in experiment_ratios.items():\n",
    "    if ratio is not None:\n",
    "        print(f\"  {exp}: {ratio}\")\n",
    "for exp, s in experiment_squeeze.items():\n",
    "    if ratio is not None:\n",
    "        print(f\"  {exp}: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing concat_global with 'radius':\n",
      "     time    packing      sasa    radius       experiment  ratioB  squeeze\n",
      "0     0.0  16.260718  2.367655  2.640704  motor2m_frac-10      10        9\n",
      "1  1000.0  16.695486  2.230225  2.611278  motor2m_frac-10      10        9\n",
      "2  2000.0  16.919118  2.190415  2.611726  motor2m_frac-10      10        9\n",
      "3  3000.0  16.977865  2.128425  2.610530  motor2m_frac-10      10        9\n",
      "4  4000.0  17.047296  2.123235  2.619862  motor2m_frac-10      10        9\n",
      "\n",
      "Testing concat_all:\n",
      "[WARNING] Partial data for motor2m_frac2-10 (squeeze=9, ratioB=10): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_frac2-90 (squeeze=9, ratioB=90): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_frac3-0 (squeeze=9, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_frac3-10 (squeeze=9, ratioB=10): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_frac3-90 (squeeze=9, ratioB=90): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_frac4-90 (squeeze=9, ratioB=90): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze10_frac-0 (squeeze=12, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze10_frac-10 (squeeze=12, ratioB=10): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze10_frac-50 (squeeze=12, ratioB=90): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze10_frac-90 (squeeze=12, ratioB=90): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze10_frac2-50 (squeeze=12, ratioB=50): missing 6/11 → ['g-r', 'sasa', 'torsion', 'torsion-alpha', 'torsion-phi', 'torsion-theta']\n",
      "[WARNING] Partial data for motor2m_squeeze12_frac-0_2 (squeeze=9, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze12_frac-0_3 (squeeze=9, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for motor2m_squeeze14_frac-0_2 (squeeze=9, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for test_nr2 (squeeze=15, ratioB=0): missing 1/11 → ['torsion']\n",
      "[WARNING] Partial data for test_nr3 (squeeze=15, ratioB=0): missing 1/11 → ['torsion']\n",
      "         experiment  ratioB molecule  squeeze  torsion-phi  std-torsion-phi  \\\n",
      "0   motor2m_frac-10      10        A        9   -19.180691         5.542503   \n",
      "1   motor2m_frac-10      10        B        9   121.972910        91.875310   \n",
      "2  motor2m_frac2-10      10        A        9   -19.145314         6.573715   \n",
      "3  motor2m_frac2-10      10        B        9   151.525840         3.488721   \n",
      "4  motor2m_frac2-90      90        A        9   -20.457817         5.489535   \n",
      "\n",
      "   voronota-volume  std-voronota-volume    packing    torsion  ...  \\\n",
      "0       576.879447            39.381025  17.297524  11.997061  ...   \n",
      "1       575.986824            43.563742  17.297524   9.398119  ...   \n",
      "2       574.884392            35.817473  16.954748        NaN  ...   \n",
      "3       585.653179            48.678569  16.954748        NaN  ...   \n",
      "4       559.923639            24.184726  17.148262        NaN  ...   \n",
      "\n",
      "   voronota-area  std-voronota-area        RG    std-RG  torsion-theta  \\\n",
      "0     283.231078          86.249263  8.603780  0.719703     -97.573144   \n",
      "1     334.440003          37.247948  8.629517  0.744132     -31.723187   \n",
      "2     286.849411          83.665279  8.647189  0.628021     -88.280234   \n",
      "3     322.398251          45.801734  8.652479  0.911916     -41.499629   \n",
      "4     360.164420          19.367706  8.640262  0.603722     -58.799600   \n",
      "\n",
      "   std-torsion-theta       g-r  torsion-alpha  std-torsion-alpha      sasa  \n",
      "0          61.287380  0.928428     -67.593495           5.821305  1.972909  \n",
      "1          28.777084  0.928428    -149.960969          24.696975  1.972909  \n",
      "2          68.345070  0.962380     -67.879967           6.712937  1.995068  \n",
      "3           6.545003  0.962380    -157.348896           4.088295  1.995068  \n",
      "4          91.309001  0.205873     -69.999017           7.739976  2.023674  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "def concat_global(data_path=Path('../data')):\n",
    "    \"\"\"\n",
    "    Concatenate a global parameter across all valid experiments.\n",
    "    \n",
    "    Args:\n",
    "        param_name: Name of the global parameter\n",
    "        data_path: Path to data directory\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: time, parameter, experiment, ratio\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for exp_name in valid_experiments:\n",
    "        # Handle special parameters\n",
    "\n",
    "        # Load box_z data and convert to packing\n",
    "        file_path = data_path / f\"{exp_name}_box-z.csv\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = ['time', 'box-z']\n",
    "        df['packing'] = NMOLS / (df['box-z'] / 10) # Box in Å to packing in mols/nm\n",
    "        df = df[['time', 'packing']]  # Only keep time and packing\n",
    "        file_path = data_path / f\"{exp_name}_sasa.csv\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "        df2 = pd.read_csv(file_path)\n",
    "        df2.columns = ['time', 'sasa']\n",
    "        df['sasa'] = df2['sasa'] / NMOLS # sasa per motor\n",
    "        file_path = data_path / f\"{exp_name}_radius.csv\"\n",
    "        if not file_path.exists():\n",
    "            continue\n",
    "        df3 = pd.read_csv(file_path)\n",
    "        df3.columns = ['time', 'radius']\n",
    "        df['radius'] = df3['radius'] / 10 # Make to nm     \n",
    "            \n",
    "\n",
    "\n",
    "        # Add experiment name\n",
    "        df['experiment'] = exp_name\n",
    "        \n",
    "        # Get ratio information\n",
    "        df['ratioB'] = get_experiment_ratio(exp_name)\n",
    "        df['squeeze'] = get_experiment_squeeze(exp_name)\n",
    "            \n",
    "        all_data.append(df)\n",
    "    \n",
    "    if not all_data:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "        \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def concat_all(data_path=Path('../data'), return_missing: bool = False):\n",
    "    \"\"\"\n",
    "    Concatenate all parameters across all valid experiments.\n",
    "    \n",
    "    Creates a summary DataFrame with averages for the last 50% of time frames,\n",
    "    separated by molecule type (A and B).\n",
    "    \n",
    "    Also detects experiments with partial data (some but not all parameters present)\n",
    "    and prints a warning. If return_missing=True, also returns a DataFrame report.\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to data directory\n",
    "        return_missing: If True, return (result_df, missing_report_df)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: experiment, ratioB, molecule, squeeze, <params...>, std-<local params...>\n",
    "        If return_missing=True: (result_df, missing_report_df)\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    missing_rows = []\n",
    "\n",
    "    # Build expected parameter set (note: 'box-z' becomes 'packing' after transform)\n",
    "    expected_params = set()\n",
    "    for p in parameter_names:\n",
    "        expected_params.add('packing' if p == 'box-z' else p)\n",
    "    for exp_name in valid_experiments:\n",
    "        ratio = get_experiment_ratio(exp_name)\n",
    "        squeeze = get_experiment_squeeze(exp_name)\n",
    "\n",
    "        result_A = {'experiment': exp_name, 'ratioB': ratio, 'molecule': 'A', 'squeeze': squeeze}\n",
    "        result_B = {'experiment': exp_name, 'ratioB': ratio, 'molecule': 'B', 'squeeze': squeeze}\n",
    "\n",
    "        found_params = set()  # track successfully computed param names for this experiment\n",
    "\n",
    "        for param_name in parameter_names:\n",
    "            is_global = False\n",
    "            is_torsion = False\n",
    "\n",
    "            file_path = data_path / f\"{exp_name}_{param_name}.csv\"\n",
    "            if not file_path.exists():\n",
    "                # Missing raw file for this parameter in this experiment\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            is_global = 'resid' not in df.columns\n",
    "            is_torsion = param_name.startswith('torsion')\n",
    "\n",
    "            # ----- special transforms / normalization -----\n",
    "            if param_name == 'box-z':\n",
    "                # Convert to packing (motors / nm) from box-z in Å\n",
    "                df.columns = ['time', 'packing']\n",
    "                df['packing'] = NMOLS / (df['packing'] / 10.0)\n",
    "                param_name = 'packing'\n",
    "                is_global = True\n",
    "\n",
    "            elif param_name == 'sasa':\n",
    "                df.columns = ['time', 'sasa']\n",
    "                df['sasa'] = df['sasa'] / NMOLS\n",
    "                is_global = True\n",
    "\n",
    "            elif param_name == 'radius':\n",
    "                df.columns = ['time', 'radius']\n",
    "                df['radius'] = df['radius'] / 10\n",
    "                df['diameter'] = 2*df['radius']\n",
    "                # If it were Å, we would convert by /10. Keep comment to avoid future confusion.\n",
    "                is_global = True\n",
    "\n",
    "            elif is_torsion and 'resid' in df.columns:\n",
    "                # Mirror torsions for resid 2 and 4: ONLY angle/time columns, not 'resid'\n",
    "                angle_cols = [c for c in df.columns if c != 'resid']\n",
    "                mask = df['resid'].isin([2, 4])\n",
    "                if mask.sum() < 2:\n",
    "                    print(f\"Warning: torsion mirror check failed or sparse for {exp_name}_{param_name}\")\n",
    "                df.loc[mask, angle_cols] = df.loc[mask, angle_cols] * -1\n",
    "\n",
    "            # ----- last 50% of frames & aggregation -----\n",
    "            if is_global:\n",
    "                total_frames = len(df)\n",
    "                if total_frames < 2:\n",
    "                    # too short to split — skip but record partial\n",
    "                    continue\n",
    "                last_half_start = total_frames // 2\n",
    "                df = df.iloc[last_half_start:]\n",
    "\n",
    "                # standardize 2-col format: ['time', param_name]\n",
    "                if len(df.columns) >= 2:\n",
    "                    df.columns = ['time', param_name] + list(df.columns[2:])\n",
    "\n",
    "                mean_value = df[param_name].mean()\n",
    "\n",
    "                result_A[param_name] = mean_value\n",
    "                result_B[param_name] = mean_value\n",
    "                found_params.add(param_name)\n",
    "\n",
    "            else:\n",
    "                if 'resid' not in df.columns:\n",
    "                    print(f\"Error; resid not in {exp_name}_{param_name}\")\n",
    "                    continue\n",
    "\n",
    "                # Rename columns to standardized format - first column is resid, rest are timesteps\n",
    "                time_columns = list(range(len(df.columns) - 1))\n",
    "                df.columns = ['resid'] + time_columns\n",
    "\n",
    "                # Get last 50% of time columns\n",
    "                time_cols = [col for col in df.columns if col != 'resid']\n",
    "                if len(time_cols) < 2:\n",
    "                    continue\n",
    "                last_half_cols = time_cols[len(time_cols)//2:]\n",
    "\n",
    "                # Map resids to molecule types (A: 1,2; B: 3,4)\n",
    "                df['type'] = df['resid'].map({1: 'A', 2: 'A', 3: 'B', 4: 'B'})\n",
    "\n",
    "                # A\n",
    "                df_A = df[df['type'] == 'A']\n",
    "                if not df_A.empty:\n",
    "                    A_time_avg = df_A[last_half_cols].mean(axis=1)\n",
    "                    result_A[param_name] = A_time_avg.mean()\n",
    "                    result_A[f'std-{param_name}'] = A_time_avg.std()\n",
    "                    found_params.add(param_name)\n",
    "\n",
    "                # B\n",
    "                df_B = df[df['type'] == 'B']\n",
    "                if not df_B.empty:\n",
    "                    B_time_avg = df_B[last_half_cols].mean(axis=1)\n",
    "                    result_B[param_name] = B_time_avg.mean()\n",
    "                    result_B[f'std-{param_name}'] = B_time_avg.std()\n",
    "                    found_params.add(param_name)\n",
    "\n",
    "        # Record results\n",
    "        if len(result_A) > 3:\n",
    "            all_results.append(result_A)\n",
    "        if len(result_B) > 3:\n",
    "            all_results.append(result_B)\n",
    "\n",
    "        # ----- missing data detection for this experiment -----\n",
    "        missing = sorted(expected_params - found_params)\n",
    "        present = sorted(found_params)\n",
    "        completeness = (len(found_params) / max(1, len(expected_params)))\n",
    "\n",
    "        if missing and present:\n",
    "            print(f\"[WARNING] Partial data for {exp_name} (squeeze={squeeze}, ratioB={ratio}): \"\n",
    "                  f\"missing {len(missing)}/{len(expected_params)} → {missing}\")\n",
    "\n",
    "        missing_rows.append({\n",
    "            'experiment': exp_name,\n",
    "            'squeeze': squeeze,\n",
    "            'ratioB': ratio,\n",
    "            'present_n': len(present),\n",
    "            'expected_n': len(expected_params),\n",
    "            'completeness': completeness,\n",
    "            'present_params': present,\n",
    "            'missing_params': missing,\n",
    "        })\n",
    "\n",
    "    # Final tables\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    missing_report_df = pd.DataFrame(missing_rows).sort_values(['squeeze', 'ratioB', 'experiment']).reset_index(drop=True)\n",
    "\n",
    "    if return_missing:\n",
    "        return result_df, missing_report_df\n",
    "    return result_df\n",
    "\n",
    "print(\"Testing concat_global with 'radius':\")\n",
    "global_df = concat_global()\n",
    "print(global_df.head())\n",
    "print(\"\\nTesting concat_all:\")\n",
    "all_df, missing = concat_all(return_missing=True)\n",
    "print(all_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  parameter  squeeze  ratioB      mean  count        CI molecule  n_mols\n",
      "0    radius        9     0.0  2.634849    4.0  0.022224      NaN     NaN\n",
      "1    radius        9    10.0  2.611403    3.0  0.010393      NaN     NaN\n",
      "2    radius        9    90.0  2.640702    3.0  0.036610      NaN     NaN\n",
      "3    radius       12     0.0  2.758679    1.0  0.000000      NaN     NaN\n",
      "4    radius       12    10.0  2.789449    1.0  0.000000      NaN     NaN\n",
      "5    radius       12    50.0  2.836411    1.0  0.000000      NaN     NaN\n",
      "6    radius       12    90.0  2.907397    2.0  0.046250      NaN     NaN\n",
      "7    radius       15     0.0  2.952352    2.0  0.006302      NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# constants\n",
    "NMOLS = 200\n",
    "Z_CI = 1.96\n",
    "\n",
    "def summarize_parameters(all_df):\n",
    "    \"\"\"\n",
    "    Compute mean and 95% CI per (squeeze, ratioB) for global parameters and\n",
    "    per (squeeze, ratioB, molecule) for local parameters (A/B),\n",
    "    using replicate-level summaries in all_df.\n",
    "    \"\"\"\n",
    "    global_params = ['radius', 'sasa', 'packing', 'diameter']\n",
    "    local_params = [c for c in all_df.columns\n",
    "                    if not c.startswith('std-')\n",
    "                    and c not in global_params\n",
    "                    and c not in ['experiment','ratioB','molecule','squeeze']]\n",
    "\n",
    "        # --- compute derived density per experiment ---\n",
    "    all_df = all_df.copy()\n",
    "    all_df['density'] = all_df['packing']/ (np.pi * all_df['radius']**2)\n",
    "    global_params.append('density')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ---------- GLOBAL PARAMETERS ----------\n",
    "    for p in global_params:\n",
    "        if p not in all_df.columns:\n",
    "            continue\n",
    "        df = all_df[['squeeze', 'ratioB', p]].dropna()\n",
    "        if df.empty:\n",
    "            continue\n",
    "        grouped = df.groupby(['squeeze', 'ratioB'])[p]\n",
    "        res = grouped.agg(['mean', 'std', 'count']).reset_index()\n",
    "        res['count'] = res['count'] / 2 # We have both molA and molB which are accounted for here\n",
    "        res['sem'] = res['std'] / np.sqrt(res['count'])\n",
    "        res['CI'] = Z_CI * res['sem']\n",
    "        res['parameter'] = p\n",
    "        results.append(res[['parameter', 'squeeze', 'ratioB', 'mean', 'count','CI']])\n",
    "\n",
    "    # ---------- LOCAL PARAMETERS (per squeeze, ratioB, molecule) ----------\n",
    "    for p in local_params:\n",
    "        std_col = f'std-{p}'\n",
    "        if std_col not in all_df.columns:\n",
    "            continue\n",
    "\n",
    "        df = all_df[['squeeze','ratioB','molecule',p,std_col]].dropna()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = df.groupby(['squeeze','ratioB','molecule'])\n",
    "        tmp = []\n",
    "\n",
    "        for (sq, rb, mol), g in grouped:\n",
    "            # determine group molecule count from ratioB (assumed percent)\n",
    "            nB = int(round((rb/100.0) * NMOLS))\n",
    "            nA = NMOLS - nB\n",
    "            n_mols = nB if mol == 'B' else nA\n",
    "\n",
    "            # if a group has zero molecules (e.g., ratioB=0 and mol=='B'), skip safely\n",
    "            if n_mols <= 1:\n",
    "                print(f\"[warn] n_mols <= 1 for (squeeze={sq}, ratioB={rb}, molecule={mol}); skipping {p}\")\n",
    "                continue\n",
    "\n",
    "            k = len(g)  # number of replicate experiments in this cell\n",
    "\n",
    "            mean = g[p].mean()\n",
    "\n",
    "            # pooled within-fibre variance across replicates (use correct n per replicate)\n",
    "            # since n_mols is constant within a (sq, rb, mol) cell, this simplifies,\n",
    "            # but we keep the general pooled formula for safety:\n",
    "            vd_pooled_num = ((n_mols - 1) * (g[std_col] ** 2)).sum()\n",
    "            vd_pooled_den = k * (n_mols - 1)\n",
    "            vd_pooled = vd_pooled_num / vd_pooled_den if vd_pooled_den > 0 else np.nan\n",
    "\n",
    "            # variance between replicate means\n",
    "            vd_between = g[p].var(ddof=1) if k > 1 else 0.0\n",
    "\n",
    "            # component from within-molecule variance for the mean of a single replicate\n",
    "            within_component = vd_pooled / n_mols if np.isfinite(vd_pooled) else 0.0\n",
    "\n",
    "            # conservative SEM for the averaged mean over k replicates:\n",
    "            # take the dominating component, then divide by k\n",
    "            sem = np.sqrt(max(within_component, vd_between) / k)\n",
    "            ci  = Z_CI * sem\n",
    "\n",
    "            tmp.append(dict(parameter=p, squeeze=sq, ratioB=rb, molecule=mol,\n",
    "                            mean=mean, CI=ci, count=k, n_mols=n_mols))\n",
    "\n",
    "        if tmp:\n",
    "            results.append(pd.DataFrame(tmp))\n",
    "\n",
    "    summary = pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "    return summary\n",
    "\n",
    "\n",
    "# usage\n",
    "summary_df = summarize_parameters(all_df)\n",
    "print(summary_df[summary_df['parameter'] == 'radius'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Squeeze = 9\n",
      "\n",
      "R$_g$ (nm)                          &  8.68 $\\pm$ 0.046 &  8.87 $\\pm$ 0.059 &\n",
      "Volume (nm$^3$/motor)               & 576.99 $\\pm$ 2.900 & 573.28 $\\pm$ 4.291 &\n",
      "Area (nm$^2$/motor)                 & 264.95 $\\pm$ 6.106 & 268.41 $\\pm$ 7.286 &\n",
      "Radius (nm)                         &  2.63 $\\pm$ 0.022 &  2.64 $\\pm$ 0.037 &\n",
      "Density (motor/nm$^3$)              &  0.79 $\\pm$ 0.004 &  0.79 $\\pm$ 0.015 &\n",
      "SASA (nm$^2$/motor)                 &  2.06 $\\pm$ 0.070 &  2.03 $\\pm$ 0.014 &\n",
      "Axial density (motors/nm)           & 17.13 $\\pm$ 0.365 & 17.20 $\\pm$ 0.300 &\n",
      "\n",
      "### Squeeze = 12\n",
      "\n",
      "R$_g$ (nm)                          &  8.82 $\\pm$ 0.087 &  9.00 $\\pm$ 0.055 &\n",
      "Volume (nm$^3$/motor)               & 574.29 $\\pm$ 5.234 & 565.36 $\\pm$ 17.261 &\n",
      "Area (nm$^2$/motor)                 & 262.49 $\\pm$ 13.105 & 295.68 $\\pm$ 36.361 &\n",
      "Radius (nm)                         &  2.76 $\\pm$ 0.000 &  2.91 $\\pm$ 0.046 &\n",
      "Density (motor/nm$^3$)              &  0.80 $\\pm$ 0.000 &  0.77 $\\pm$ 0.027 &\n",
      "SASA (nm$^2$/motor)                 &  1.92 $\\pm$ 0.000 &  1.90 $\\pm$ 0.013 &\n",
      "Axial density (motors/nm)           & 19.07 $\\pm$ 0.000 & 20.40 $\\pm$ 0.056 &\n",
      "\n",
      "### Squeeze = 15\n",
      "\n",
      "R$_g$ (nm): missing data for ratio 0 or 90\n",
      "Volume (nm$^3$/motor): missing data for ratio 0 or 90\n",
      "Area (nm$^2$/motor): missing data for ratio 0 or 90\n",
      "Radius (nm): missing data for ratio 0 or 90\n",
      "Density (motor/nm$^3$): missing data for ratio 0 or 90\n",
      "SASA (nm$^2$/motor): missing data for ratio 0 or 90\n",
      "Axial density (motors/nm): missing data for ratio 0 or 90\n"
     ]
    }
   ],
   "source": [
    "params_order = [\n",
    "    (\"RG\", \"R$_g$ (nm)\"),\n",
    "    (\"voronota-volume\", \"Volume (nm$^3$/motor)\"),\n",
    "    (\"voronota-area\", \"Area (nm$^2$/motor)\"),\n",
    "    (\"radius\", \"Radius (nm)\"),\n",
    "    (\"density\", \"Density (motor/nm$^3$)\"),\n",
    "    (\"sasa\", \"SASA (nm$^2$/motor)\"),\n",
    "    (\"packing\", \"Axial density (motors/nm)\"),\n",
    "]\n",
    "\n",
    "for squeeze, sdf in summary_df.groupby(\"squeeze\"):\n",
    "    print(f\"\\n### Squeeze = {squeeze}\\n\")\n",
    "    for p, label in params_order:\n",
    "        sub = sdf[sdf[\"parameter\"] == p]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # detect if parameter is local (has molecule column)\n",
    "        is_local = \"molecule\" in sub.columns and sub[\"molecule\"].notna().any()\n",
    "\n",
    "        if is_local:\n",
    "            # molecule A when ratioB = 0, molecule B when ratioB = 90\n",
    "            row0 = sub[(sub[\"ratioB\"] == 0) & (sub[\"molecule\"] == \"A\")]\n",
    "            row90 = sub[(sub[\"ratioB\"] == 90) & (sub[\"molecule\"] == \"B\")]\n",
    "        else:\n",
    "            # global parameters have no molecule column\n",
    "            row0 = sub[sub[\"ratioB\"] == 0]\n",
    "            row90 = sub[sub[\"ratioB\"] == 90]\n",
    "\n",
    "        if row0.empty or row90.empty:\n",
    "            print(f\"{label}: missing data for ratio 0 or 90\")\n",
    "            continue\n",
    "\n",
    "        mean0, ci0 = row0.iloc[0][[\"mean\", \"CI\"]]\n",
    "        mean90, ci90 = row90.iloc[0][[\"mean\", \"CI\"]]\n",
    "\n",
    "        print(\n",
    "            f\"{label:<35s} & \"\n",
    "            f\"{mean0:5.2f} $\\\\pm$ {ci0:4.3f} & \"\n",
    "            f\"{mean90:5.2f} $\\\\pm$ {ci90:4.3f} &\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[tbp]\n",
      "    \\centering\n",
      "    \\small\n",
      "    \\caption{Summary across squeezes and excitation ratios (MMa = ratioB 0\\%, MMb = ratioB 90\\%). Errors are 95\\% confidence intervals across replicate fibres.}\n",
      "    \\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "    \\hline\n",
      "    \\textbf{Measurement}  & \\multicolumn{2}{c}{\\textbf{squeeze 9}} & \\multicolumn{2}{c}{\\textbf{squeeze 12}} & \\multicolumn{2}{c}{\\textbf{squeeze 15}} \\\\\n",
      "    \\hline\n",
      "      & \\textbf{MMa} & \\textbf{MMb} & \\textbf{MMa} & \\textbf{MMb} & \\textbf{MMa} & \\textbf{MMb} \\\\\n",
      "    \\hline\n",
      "    Diameter (nm) & 5.27 $\\pm$ 0.04 & 5.28 $\\pm$ 0.07 & 5.52 $\\pm$ 0.00 & 5.81 $\\pm$ 0.09 & 5.90 $\\pm$ 0.01 & – \\\\ \\hline\n",
      "    Axial Density (motors/nm) & 17.13 $\\pm$ 0.37 & 17.20 $\\pm$ 0.30 & 19.07 $\\pm$ 0.00 & 20.40 $\\pm$ 0.06 & 21.41 $\\pm$ 0.46 & – \\\\ \\hline\n",
      "    Volumetric Density (motors/nm$^3$) & 0.79 $\\pm$ 0.00 & 0.79 $\\pm$ 0.01 & 0.80 $\\pm$ 0.00 & 0.77 $\\pm$ 0.03 & 0.78 $\\pm$ 0.02 & – \\\\ \\hline\n",
      "    SASA (nm$^2$/motor) & 2.06 $\\pm$ 0.07 & 2.03 $\\pm$ 0.01 & 1.92 $\\pm$ 0.00 & 1.90 $\\pm$ 0.01 & 1.87 $\\pm$ 0.03 & – \\\\ \\hline\n",
      "    Molecular radius of gyration (\\AA) & 8.68 $\\pm$ 0.05 & 8.87 $\\pm$ 0.06 & 8.82 $\\pm$ 0.09 & 9.00 $\\pm$ 0.05 & 8.94 $\\pm$ 0.06 & – \\\\ \\hline\n",
      "    Molecular core volume (\\AA$^3$) & 577 $\\pm$ 3 & 573 $\\pm$ 4 & 574 $\\pm$ 5 & 565 $\\pm$ 17 & 636 $\\pm$ 123 & – \\\\ \\hline\n",
      "    Molecular core area (\\AA$^2$) & 265 $\\pm$ 6 & 268 $\\pm$ 7 & 262 $\\pm$ 13 & 296 $\\pm$ 36 & 296 $\\pm$ 69 & – \\\\ \\hline\n",
      "    \\end{tabular}\n",
      "    \\label{table:fibre_characteristics_by_squeeze_ratio}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- configure rows: (parameter, label, decimals, transform(mean, CI)->(mean, CI))\n",
    "ROWS = [\n",
    "    (\"radius\",           \"Diameter (nm)\",                         2, lambda m, c: (2*m, 2*c)),\n",
    "    (\"packing\",          \"Axial Density (motors/nm)\",             2, lambda m, c: (m, c)),\n",
    "    (\"density\",          \"Volumetric Density (motors/nm$^3$)\",    2, lambda m, c: (m, c)),\n",
    "    (\"sasa\",             \"SASA (nm$^2$/motor)\",                   2, lambda m, c: (m, c)),\n",
    "    (\"RG\",               \"Molecular radius of gyration (\\\\AA)\",   2, lambda m, c: (m, c)),\n",
    "    (\"voronota-volume\",  \"Molecular core volume (\\\\AA$^3$)\",      0, lambda m, c: (m, c)),\n",
    "    (\"voronota-area\",    \"Molecular core area (\\\\AA$^2$)\",        0, lambda m, c: (m, c)),\n",
    "]\n",
    "\n",
    "SQUEEZES = [9, 12, 15]\n",
    "SUBCOLS  = [\"MMa\", \"MMb\"]                 # MMa=ratioB 0, MMb=ratioB 90\n",
    "RATIO_MAP = {\"MMa\": 0, \"MMb\": 90}\n",
    "\n",
    "def _fmt(mean, ci, decimals):\n",
    "    if np.isnan(mean) or np.isnan(ci):\n",
    "        return \"–\"\n",
    "    q = f\"{{:.{decimals}f}}\"\n",
    "    return f\"{q.format(mean)} $\\\\pm$ {q.format(ci)}\"\n",
    "\n",
    "def _cell_value(sub_df, param, squeeze, sublabel):\n",
    "    \"\"\"Return (mean, CI) for a param/squeeze/subcol, respecting local/global molecule filtering.\"\"\"\n",
    "    ratio = RATIO_MAP[sublabel]\n",
    "    sdf = sub_df[sub_df[\"parameter\"] == param]\n",
    "    if sdf.empty:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # detect local vs global per your rule: local has a 'molecule' column with any non-null values\n",
    "    is_local = (\"molecule\" in sdf.columns) and sdf[\"molecule\"].notna().any()\n",
    "\n",
    "    if is_local:\n",
    "        mol = \"A\" if ratio == 0 else \"B\"\n",
    "        view = sdf[(sdf[\"squeeze\"] == squeeze) & (sdf[\"ratioB\"] == ratio) & (sdf[\"molecule\"] == mol)]\n",
    "    else:\n",
    "        view = sdf[(sdf[\"squeeze\"] == squeeze) & (sdf[\"ratioB\"] == ratio)]\n",
    "\n",
    "    if view.empty:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # if multiple rows (replicate groups), average defensively\n",
    "    return view[\"mean\"].mean(), view[\"CI\"].mean()\n",
    "\n",
    "# ---- compose LaTeX\n",
    "header_main = \" & \" + \" & \".join([f\"\\\\multicolumn{{2}}{{c}}{{\\\\textbf{{squeeze {sq}}}}}\" for sq in SQUEEZES]) + \" \\\\\\\\\"\n",
    "header_sub  = \" & \" + \" & \".join([f\"\\\\textbf{{MMa}} & \\\\textbf{{MMb}}\" for _ in SQUEEZES]) + \" \\\\\\\\\"\n",
    "\n",
    "lines = []\n",
    "lines.append(\"\\\\begin{table*}[tbp]\")\n",
    "lines.append(\"    \\\\centering\")\n",
    "lines.append(\"    \\\\small\")\n",
    "lines.append(\"    \\\\caption{Summary across squeezes and excitation ratios (MMa = ratioB 0\\\\%, MMb = ratioB 90\\\\%). Errors are 95\\\\% confidence intervals across replicate fibres.}\")\n",
    "lines.append(\"    \\\\begin{tabular}{|c|\" + \"c|\" * (len(SQUEEZES)*2) + \"}\")\n",
    "lines.append(\"    \\\\hline\")\n",
    "lines.append(\"    \\\\textbf{Measurement} \" + header_main)\n",
    "lines.append(\"    \\\\hline\")\n",
    "lines.append(\"     \" + header_sub)\n",
    "lines.append(\"    \\\\hline\")\n",
    "\n",
    "for param, label, decs, transform in ROWS:\n",
    "    row_cells = []\n",
    "    for sq in SQUEEZES:\n",
    "        for sublabel in SUBCOLS:\n",
    "            # special case: no MMb for squeeze=15\n",
    "            if sq == 15 and sublabel == \"MMb\":\n",
    "                row_cells.append(\"–\")\n",
    "                continue\n",
    "            m, c = _cell_value(summary_df, param, sq, sublabel)\n",
    "            if not (np.isnan(m) or np.isnan(c)):\n",
    "                m, c = transform(m, c)\n",
    "            row_cells.append(_fmt(m, c, decs))\n",
    "    line = f\"    {label} & \" + \" & \".join(row_cells) + \" \\\\\\\\ \\\\hline\"\n",
    "    lines.append(line)\n",
    "\n",
    "lines.append(\"    \\\\end{tabular}\")\n",
    "lines.append(\"    \\\\label{table:fibre_characteristics_by_squeeze_ratio}\")\n",
    "lines.append(\"\\\\end{table*}\")\n",
    "\n",
    "print(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions\n",
    "### var(squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from md_styler import MDStyler\n",
    "\n",
    "# --- style & fixed colors\n",
    "sty = MDStyler().apply()\n",
    "squeeze_colors = {9: sty.palette6[0], 12: sty.palette6[2], 15: sty.palette6[1]}\n",
    "\n",
    "# --- config\n",
    "GLOBAL_PARAMS = [\"radius\", \"sasa\", \"packing\", \"density\"]\n",
    "PARAM_LABEL = {\n",
    "    \"radius\": \"radius (nm)\",\n",
    "    \"sasa\": \"SASA per molecule (nm²)\",\n",
    "    \"packing\": \"axial density (molecules / nm)\",\n",
    "    \"density\": \"density (molecules / nm³)\",\n",
    "}\n",
    "RATIOB_TARGET = 0\n",
    "NBOOT = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "all_df['density'] = all_df['packing'] /(np.pi * all_df['radius']**2)\n",
    "# --- filter all_df to ratioB == 0 and globals\n",
    "df0 = all_df.query(\"ratioB == @RATIOB_TARGET\").copy()\n",
    "present = [p for p in GLOBAL_PARAMS if p in df0.columns]\n",
    "\n",
    "def bootstrap_rho_balanced(df_param, nboot=NBOOT, rng=rng):\n",
    "    \"\"\"Bootstrap Pearson ρ between squeeze and parameter value.\"\"\"\n",
    "    work = df_param[[\"squeeze\", \"value\"]].dropna().copy()\n",
    "    by_sq = {sq: sub.reset_index(drop=True) for sq, sub in work.groupby(\"squeeze\")}\n",
    "    squeezes_sorted = sorted(by_sq.keys())\n",
    "    rhos = np.empty(nboot, dtype=float)\n",
    "\n",
    "    for i in range(nboot):\n",
    "        xs, ys = [], []\n",
    "        for sq in squeezes_sorted:\n",
    "            sub = by_sq[sq]\n",
    "            idx = rng.integers(0, len(sub), size=len(sub))\n",
    "            vals = sub.loc[idx, \"value\"].to_numpy()\n",
    "            xs.append(np.full(len(sub), float(sq)))\n",
    "            ys.append(vals)\n",
    "        x = np.concatenate(xs)\n",
    "        y = np.concatenate(ys)\n",
    "        rhos[i], _ = pearsonr(x, y)\n",
    "\n",
    "    return float(np.mean(rhos)), tuple(np.percentile(rhos, [2.5, 97.5]))\n",
    "\n",
    "rho_rows = []\n",
    "for i, p in enumerate(present):\n",
    "    # tidy parameter subset\n",
    "    sub = df0[[\"squeeze\", p]].rename(columns={p: \"value\"}).dropna()\n",
    "    if sub.empty:\n",
    "        print(f\"[warn] No data for '{p}' at ratioB={RATIOB_TARGET}\")\n",
    "        continue\n",
    "\n",
    "    rho_mean, (rho_lo, rho_hi) = bootstrap_rho_balanced(sub)\n",
    "\n",
    "    # --- scatter plot of all raw data points\n",
    "    fig, ax = sty.fig_square()\n",
    "    for sq in sorted(sub[\"squeeze\"].unique()):\n",
    "        g = sub[sub[\"squeeze\"] == sq]\n",
    "        ax.scatter(\n",
    "            np.full(len(g), sq),\n",
    "            g[\"value\"],\n",
    "            s=16,\n",
    "            alpha=0.8,\n",
    "            color=squeeze_colors.get(int(sq), \"#777777\"),\n",
    "            label=f\"Squeeze {sq}\" if i == 0 else None,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Iterations of Scaling\")\n",
    "    ax.set_ylabel(PARAM_LABEL.get(p, p))\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False, loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    rho_rows.append(dict(parameter=p, rho=rho_mean, CI_low=rho_lo, CI_high=rho_hi))\n",
    "\n",
    "rho_df = pd.DataFrame(rho_rows).sort_values(\"rho\", ascending=False)\n",
    "rho_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_colors = {9: sty.palette6[0], 12: sty.palette6[2]}  # only 9 & 12\n",
    "\n",
    "# --- config\n",
    "GLOBAL_PARAMS = [\"radius\", \"sasa\", \"packing\", \"density\"]\n",
    "PARAM_LABEL = {\n",
    "    \"radius\": \"radius (nm)\",\n",
    "    \"sasa\": \"SASA per molecule (nm²)\",\n",
    "    \"packing\": \"axial density (molecules / nm)\",\n",
    "    \"density\": \"density (molecules / nm³)\",\n",
    "}\n",
    "NBOOT = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# --- subset to squeezes 9 & 12, keep only rows with needed columns\n",
    "df = all_df.copy()\n",
    "df = df[df[\"squeeze\"].isin([9, 12])]\n",
    "present = [p for p in GLOBAL_PARAMS if p in df.columns]\n",
    "if not present:\n",
    "    print(\"[warn] No global parameters present among\", GLOBAL_PARAMS)\n",
    "\n",
    "def bootstrap_rho_by_ratioB(df_param, nboot=NBOOT, rng=rng):\n",
    "    \"\"\"\n",
    "    Bootstrap Pearson ρ between ratioB (x) and parameter value (y),\n",
    "    balanced across squeezes 9 & 12.\n",
    "    \"\"\"\n",
    "    work = df_param[[\"squeeze\", \"ratioB\", \"value\"]].dropna().copy()\n",
    "    by_sq = {sq: sub.reset_index(drop=True) for sq, sub in work.groupby(\"squeeze\")}\n",
    "    squeezes_sorted = sorted(by_sq.keys())\n",
    "    if len(squeezes_sorted) == 0:\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "\n",
    "    rhos = np.empty(nboot, dtype=float)\n",
    "    for i in range(nboot):\n",
    "        xs, ys = [], []\n",
    "        sub = by_sq[9]\n",
    "        idx = rng.integers(0, len(sub), size=len(sub))\n",
    "        xs.append(sub.loc[idx, \"ratioB\"].to_numpy(dtype=float))\n",
    "        ys.append(sub.loc[idx, \"value\"].to_numpy(dtype=float))\n",
    "        x = np.concatenate(xs)\n",
    "        y = np.concatenate(ys)\n",
    "        rhos[i], _ = pearsonr(x, y)\n",
    "\n",
    "    return float(np.mean(rhos)), tuple(np.percentile(rhos, [2.5, 97.5]))\n",
    "\n",
    "rho_rows = []\n",
    "for i, p in enumerate(present):\n",
    "    sub = df[[\"squeeze\", \"ratioB\", p]].rename(columns={p: \"value\"}).dropna()\n",
    "    if sub.empty:\n",
    "        print(f\"[warn] No data for '{p}' with squeezes 9 & 12\")\n",
    "        continue\n",
    "\n",
    "    # --- bootstrap Pearson correlation (ratioB vs value)\n",
    "    rho_mean, (rho_lo, rho_hi) = bootstrap_rho_by_ratioB(sub)\n",
    "\n",
    "    # --- scatter of raw data points (ratioB on x), colored by squeeze\n",
    "    fig, ax = sty.fig_square()\n",
    "    for sq in (9, 12):\n",
    "        g = sub[sub[\"squeeze\"] == sq]\n",
    "        if g.empty:\n",
    "            continue\n",
    "        ax.scatter(\n",
    "            g[\"ratioB\"].astype(float),\n",
    "            g[\"value\"].astype(float),\n",
    "            s=16,\n",
    "            alpha=0.85,\n",
    "            color=squeeze_colors[sq],\n",
    "            label=f\"Scaling: {sq}\" if i == 0 else None,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Percent actuated (%)\")\n",
    "    ax.set_ylabel(PARAM_LABEL.get(p, p))\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False, loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    rho_rows.append(dict(parameter=p, rho=rho_mean, CI_low=rho_hi if np.isnan(rho_lo) else rho_lo, CI_high=rho_hi))\n",
    "\n",
    "rho_df = pd.DataFrame(rho_rows).sort_values(\"rho\", ascending=False)\n",
    "rho_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torsion angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_torsion_angles(data_path=Path('../data')):\n",
    "    \"\"\"\n",
    "    Create a single scatter plot of torsion-theta vs torsion-alpha for the last frame of each experiment.\n",
    "    Points are colored by molecule type (A vs B). KDE is drawn per molecule type on a 1/10 subsample.\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to data directory\n",
    "    \"\"\"\n",
    "    # ----- apply style (no change to the data pipeline)\n",
    "    sty = MDStyler().apply()\n",
    "    sns.reset_orig() \n",
    "\n",
    "    torsion_data = []\n",
    "\n",
    "    for exp_name in valid_experiments:\n",
    "        # Get ratio for this experiment\n",
    "        ratio = get_experiment_ratio(exp_name, data_path)\n",
    "        if ratio is None:\n",
    "            print(f\"[warn] Missing ratio for {exp_name}, skipping…\")\n",
    "            continue\n",
    "\n",
    "        # Load torsion-theta data\n",
    "        theta_file = data_path / f\"{exp_name}_torsion-theta.csv\"\n",
    "        if not theta_file.exists():\n",
    "            print(f\"[warn] Missing file: {theta_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load torsion-alpha (phi) data\n",
    "        phi_file = data_path / f\"{exp_name}_torsion-alpha.csv\"\n",
    "        if not phi_file.exists():\n",
    "            print(f\"[warn] Missing file: {phi_file}\")\n",
    "            continue\n",
    "\n",
    "        df_theta = pd.read_csv(theta_file)\n",
    "        df_phi   = pd.read_csv(phi_file)\n",
    "\n",
    "        # Basic structural checks (same shape & resid column)\n",
    "        if df_theta.shape != df_phi.shape:\n",
    "            print(f\"[warn] Structure mismatch for {exp_name} (theta {df_theta.shape} vs alpha {df_phi.shape}), skipping…\")\n",
    "            continue\n",
    "        if \"resid\" not in df_theta.columns or \"resid\" not in df_phi.columns:\n",
    "            print(f\"[warn] 'resid' column missing for {exp_name}, skipping…\")\n",
    "            continue\n",
    "\n",
    "        # Last columns (last frame)\n",
    "        last_theta_col = df_theta.columns[-1]\n",
    "        last_phi_col   = df_phi.columns[-1]\n",
    "\n",
    "        # Extract per-molecule values\n",
    "        for idx, row in df_theta.iterrows():\n",
    "            resid = row[\"resid\"]\n",
    "\n",
    "            # Ensure resid exists in phi table at same row or anywhere\n",
    "            if resid not in df_phi[\"resid\"].values:\n",
    "                print(f\"[warn] resid {resid} not found in alpha for {exp_name}, skipping this resid…\")\n",
    "                continue\n",
    "\n",
    "            theta_val = row[last_theta_col]\n",
    "            phi_val   = df_phi.iloc[idx, -1]\n",
    "\n",
    "            # mirror for B-R that relaxes to A-S (domain-specific rule)\n",
    "            if resid in [2, 3]:\n",
    "                theta_val *= -1\n",
    "                phi_val   *= -1\n",
    "\n",
    "            # simple wrapping/cleaning to keep angles in expected ranges\n",
    "            if pd.notna(theta_val) and theta_val > 100:\n",
    "                theta_val -= 360\n",
    "            if pd.notna(phi_val) and phi_val < -150:\n",
    "                phi_val += 360\n",
    "\n",
    "            # Map resid → molecule type\n",
    "            molecule = 'A' if resid in [1, 2] else 'B'\n",
    "\n",
    "            torsion_data.append({\n",
    "                \"experiment\": exp_name,\n",
    "                \"resid\": resid,\n",
    "                \"molecule\": molecule,\n",
    "                \"ratioB\": ratio,\n",
    "                \"theta\": theta_val,\n",
    "                \"alpha\": phi_val\n",
    "            })\n",
    "\n",
    "    torsion_df = pd.DataFrame(torsion_data)\n",
    "\n",
    "    if torsion_df.empty:\n",
    "        print(\"[warn] No torsion data collected\")\n",
    "        return None\n",
    "\n",
    "    # sanity checks\n",
    "    if torsion_df[[\"theta\", \"alpha\"]].isna().any().any():\n",
    "        n_nan = torsion_df[[\"theta\", \"alpha\"]].isna().sum().sum()\n",
    "        print(f\"[warn] Found {n_nan} NaN values in theta/alpha. They will be ignored by plotting.\")\n",
    "\n",
    "    # ---- plotting (style-only changes)\n",
    "    # keep original call signature (single axes), but our rcParams are already active\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # choose styler colors (A = cyan-ish, B = deep blue from PBC box)\n",
    "    molecule_colors = {\n",
    "        \"A\": sty.get_color(\"cyan\"),\n",
    "        \"B\": sty.get_color(\"red\"),\n",
    "    }\n",
    "\n",
    "    # scatter (keep small marker size, thin black edge like original)\n",
    "    for molecule_type, color in molecule_colors.items():\n",
    "        subset = torsion_df[torsion_df[\"molecule\"] == molecule_type]\n",
    "        ax.scatter(\n",
    "            subset[\"theta\"], subset[\"alpha\"],\n",
    "            color=color, marker='o', s=12, alpha=0.3,\n",
    "            edgecolor='black', linewidth=0.2,\n",
    "            label=f\"Initiated as {molecule_type}\"\n",
    "        )\n",
    "\n",
    "    # KDE per molecule type on a 1/10 subsample (if seaborn is available)\n",
    "    for molecule_type, color in molecule_colors.items():\n",
    "        subset = torsion_df[torsion_df[\"molecule\"] == molecule_type]\n",
    "        # 1/10 subsample for KDE (reproducible)\n",
    "        subs = subset.sample(frac=1, random_state=0)\n",
    "        sns.kdeplot(\n",
    "            x=subs['theta'], y=subs['alpha'],\n",
    "            levels=5, linewidths=1, ax=ax,\n",
    "            color=color, alpha=0.5\n",
    "        )\n",
    "\n",
    "    # legend, labels, formatting (match original intent)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), title=\"Molecule Type\", loc='best', frameon=False)\n",
    "\n",
    "    ax.set_title('Torsion Angles by Molecule Type', fontsize=24)\n",
    "    ax.set_xlabel(r'Torsion $\\theta$ (°)')\n",
    "    ax.set_ylabel(r'Torsion $\\alpha$ (°)')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # original script enabled grid with light alpha\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # dynamic limits consistent with original max-range logic\n",
    "    max_range = max(\n",
    "        abs(torsion_df['theta'].max()), abs(torsion_df['theta'].min()),\n",
    "        abs(torsion_df['alpha'].max()), abs(torsion_df['alpha'].min())\n",
    "    )\n",
    "    # (keep auto limits unless you want to set explicit ones as in your commented code)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax, torsion_df\n",
    "\n",
    "fig, ax, df = plot_torsion_angles()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_gr.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, List, Tuple, Optional\n",
    "\n",
    "from scipy.signal import savgol_filter  # for Savitzky–Golay smoothing\n",
    "\n",
    "@dataclass\n",
    "class GRAnalysisResult:\n",
    "    r: np.ndarray\n",
    "    weighted_gr_df: pd.DataFrame\n",
    "    smoothed_df: Optional[pd.DataFrame]\n",
    "    peaks: Dict[str, Dict[str, float]]\n",
    "    weighted_gr: Dict[str, np.ndarray]\n",
    "    weighted_std: Dict[str, np.ndarray]\n",
    "    used_experiments: List[str]\n",
    "    messages: List[str]\n",
    "\n",
    "\n",
    "def analyze_weighted_gr_styled(\n",
    "    experiment_ratios: Dict[str, float],\n",
    "    data_dir: str = \"../data\",\n",
    "    NMOLS: int = 200,\n",
    "    r_range: Optional[Tuple[float, float]] = None,\n",
    "    use_ordered_pairs: bool = True,   # True keeps your N_i*(N_i-1) choice\n",
    "    savgol_window: Optional[int] = None,\n",
    "    savgol_poly: int = 3,\n",
    "    interpolate_if_mismatch: bool = True,\n",
    ") -> GRAnalysisResult:\n",
    "    \"\"\"\n",
    "    Weighted-average g(r) across experiments with optional Savitzky–Golay smoothing.\n",
    "    Returns data + diagnostics (no plotting). To plot, call plot_weighted_gr_with_styler(...).\n",
    "    \"\"\"\n",
    "\n",
    "    msgs: List[str] = []\n",
    "\n",
    "    # ---- read all CSVs\n",
    "    experiment_data: Dict[str, pd.DataFrame] = {}\n",
    "    molecule_counts: Dict[str, Dict[int, int]] = {}\n",
    "\n",
    "    for expt, ratioB_pct in experiment_ratios.items():\n",
    "        if ratioB_pct == None:\n",
    "            continue\n",
    "        # compute counts: A vs B split, and R vs S split 50:50\n",
    "        n_A = int(round((100.0 - ratioB_pct) / 100.0 * NMOLS))\n",
    "        n_B = NMOLS - n_A\n",
    "        # split each evenly over R/S\n",
    "        N_1 = int(round(n_A / 2))  # A-R\n",
    "        N_2 = n_A - N_1            # A-S\n",
    "        N_3 = int(round(n_B / 2))  # B-R\n",
    "        N_4 = n_B - N_3            # B-S\n",
    "\n",
    "        # sanity\n",
    "        if (N_1 + N_2 + N_3 + N_4) != NMOLS:\n",
    "            msgs.append(f\"[warn] {expt}: counts round to {N_1+N_2+N_3+N_4} ≠ {NMOLS}. Adjusted by last bin.\")\n",
    "        molecule_counts[expt] = {1: N_1, 2: N_2, 3: N_3, 4: N_4}\n",
    "\n",
    "        fp = os.path.join(data_dir, f\"{expt}_g-r.csv\")\n",
    "        if not os.path.exists(fp):\n",
    "            msgs.append(f\"[warn] file not found: {fp}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(fp)\n",
    "        if \"r (Å)\" not in df.columns:\n",
    "            msgs.append(f\"[warn] {expt}: missing 'r (Å)' column\")\n",
    "            continue\n",
    "\n",
    "        experiment_data[expt] = df\n",
    "\n",
    "    used = list(experiment_data.keys())\n",
    "    if not used:\n",
    "        raise ValueError(\"No valid data files found.\")\n",
    "\n",
    "    # ---- choose base r-grid and check consistency\n",
    "    base_r = experiment_data[used[0]][\"r (Å)\"].to_numpy()\n",
    "    grids_ok = True\n",
    "    for expt, df in experiment_data.items():\n",
    "        r_here = df[\"r (Å)\"].to_numpy()\n",
    "        if r_here.shape != base_r.shape or not np.allclose(r_here, base_r, rtol=0, atol=1e-8):\n",
    "            grids_ok = False\n",
    "            msgs.append(f\"[warn] {expt}: r-grid differs from first dataset\")\n",
    "    if not grids_ok:\n",
    "        if interpolate_if_mismatch:\n",
    "            msgs.append(\"[info] interpolating all g(r) columns onto the first dataset’s r-grid\")\n",
    "            for expt, df in experiment_data.items():\n",
    "                if df[\"r (Å)\"].to_numpy().shape != base_r.shape or not np.allclose(df[\"r (Å)\"], base_r):\n",
    "                    # interpolate every g(r) column\n",
    "                    r_src = df[\"r (Å)\"].to_numpy()\n",
    "                    for col in df.columns:\n",
    "                        if col.startswith(\"g(r)\"):\n",
    "                            df[col] = np.interp(base_r, r_src, df[col].to_numpy())\n",
    "                    df[\"r (Å)\"] = base_r\n",
    "        else:\n",
    "            msgs.append(\"[error] r-grids mismatch and interpolate_if_mismatch=False\")\n",
    "\n",
    "    r = base_r.copy()\n",
    "\n",
    "    # ---- r-range mask\n",
    "    if r_range is not None:\n",
    "        rmin, rmax = r_range\n",
    "        mask = (r >= rmin) & (r <= rmax)\n",
    "        r = r[mask]\n",
    "    else:\n",
    "        mask = slice(None)\n",
    "\n",
    "    # ---- define interaction mapping (skip AR–BR and AR–BS later when plotting)\n",
    "    interaction_mapping = {\n",
    "        \"AR-AR\":   [\"g(r) 1-1\", \"g(r) 2-2\"],\n",
    "        \"AR-AS\": [\"g(r) 1-2\"],\n",
    "        \"BR-BR\":   [\"g(r) 3-3\", \"g(r) 4-4\"],\n",
    "        \"BR-BS\": [\"g(r) 3-4\"],\n",
    "    }\n",
    "\n",
    "    weighted_gr: Dict[str, np.ndarray] = {}\n",
    "    weighted_std: Dict[str, np.ndarray] = {}\n",
    "    weights_sum: Dict[str, float] = {}\n",
    "    peak_positions: Dict[str, List[Tuple[float, float]]] = {k: [] for k in interaction_mapping}\n",
    "\n",
    "    for inter, columns in interaction_mapping.items():\n",
    "        weighted_gr[inter] = np.zeros_like(r)\n",
    "        weights_sum[inter] = 0.0\n",
    "        all_values: List[np.ndarray] = []\n",
    "        all_weights: List[float] = []\n",
    "\n",
    "        for expt, df in experiment_data.items():\n",
    "            vals_here: List[np.ndarray] = []\n",
    "            weights_here: List[float] = []\n",
    "\n",
    "            for col in columns:\n",
    "                if col not in df.columns:\n",
    "                    msgs.append(f\"[warn] {expt}: column missing: {col}\")\n",
    "                    continue\n",
    "\n",
    "                # parse pair ids\n",
    "                i, j = (int(x) for x in col.split()[-1].split(\"-\"))\n",
    "                Ni = molecule_counts[expt][i]\n",
    "                Nj = molecule_counts[expt][j]\n",
    "\n",
    "                if i == j:\n",
    "                    weight = Ni * (Ni - 1) if use_ordered_pairs else Ni * (Ni - 1) / 2.0\n",
    "                else:\n",
    "                    weight = Ni * Nj\n",
    "\n",
    "                vals_here.append(df[col].to_numpy()[mask])\n",
    "                weights_here.append(float(weight))\n",
    "\n",
    "            if vals_here:\n",
    "                total_w = float(np.sum(weights_here))\n",
    "                # within-experiment weighted mean across symmetric columns\n",
    "                exp_avg = np.zeros_like(r, dtype=float)\n",
    "                for v, w in zip(vals_here, weights_here):\n",
    "                    exp_avg += v * (w / total_w)\n",
    "\n",
    "                all_values.append(exp_avg)\n",
    "                all_weights.append(total_w)\n",
    "\n",
    "                # peak for this experiment\n",
    "                pk_idx = int(np.nanargmax(exp_avg))\n",
    "                peak_positions[inter].append((float(r[pk_idx]), total_w))\n",
    "\n",
    "                weighted_gr[inter] += exp_avg * total_w\n",
    "                weights_sum[inter] += total_w\n",
    "\n",
    "        if weights_sum[inter] > 0:\n",
    "            weighted_gr[inter] /= weights_sum[inter]\n",
    "\n",
    "            # weighted variance (sample); guard small-n\n",
    "            all_values = np.asarray(all_values)\n",
    "            all_weights = np.asarray(all_weights, dtype=float)\n",
    "            if all_values.shape[0] > 1:\n",
    "                diff2 = np.zeros_like(r, dtype=float)\n",
    "                for v, w in zip(all_values, all_weights):\n",
    "                    diff2 += w * (v - weighted_gr[inter]) ** 2\n",
    "                correction = 1.0 - np.sum(all_weights**2) / (np.sum(all_weights) ** 2)\n",
    "                if correction <= 0:\n",
    "                    weighted_std[inter] = np.full_like(r, np.nan, dtype=float)\n",
    "                else:\n",
    "                    var = diff2 / (np.sum(all_weights) * correction)\n",
    "                    weighted_std[inter] = np.sqrt(var)\n",
    "            else:\n",
    "                weighted_std[inter] = np.full_like(r, np.nan, dtype=float)\n",
    "        else:\n",
    "            weighted_std[inter] = np.full_like(r, np.nan, dtype=float)\n",
    "\n",
    "    # ---- construct DataFrames\n",
    "    result_df = pd.DataFrame({\"r (Å)\": r})\n",
    "    n_expt = len(used)\n",
    "    for inter in interaction_mapping:\n",
    "        result_df[f\"g(r) {inter}\"] = weighted_gr[inter]\n",
    "        ci = 1.96 * weighted_std[inter] / np.sqrt(max(n_expt, 1))\n",
    "        result_df[f\"CI95 {inter}\"] = ci\n",
    "\n",
    "    # ---- peaks summary\n",
    "    peaks: Dict[str, Dict[str, float]] = {}\n",
    "    for inter in interaction_mapping:\n",
    "        grv = weighted_gr[inter]\n",
    "        pk_idx = int(np.nanargmax(grv))\n",
    "        peak_r = float(r[pk_idx])\n",
    "        peak_gr = float(grv[pk_idx])\n",
    "        peak_gr_ci = float(1.96 * (weighted_std[inter][pk_idx] if np.isfinite(weighted_std[inter][pk_idx]) else np.nan) / np.sqrt(max(n_expt, 1)))\n",
    "\n",
    "        if peak_positions[inter]:\n",
    "            pos, wts = zip(*peak_positions[inter])\n",
    "            pos = np.asarray(pos, dtype=float)\n",
    "            wts = np.asarray(wts, dtype=float)\n",
    "            if len(pos) > 1:\n",
    "                w_mean = float(np.sum(pos * wts) / np.sum(wts))\n",
    "                diff2 = float(np.sum(wts * (pos - w_mean) ** 2))\n",
    "                corr = 1.0 - float(np.sum(wts**2) / (np.sum(wts) ** 2))\n",
    "                if corr > 0:\n",
    "                    std_r = np.sqrt(diff2 / (np.sum(wts) * corr))\n",
    "                    peak_r_ci = float(1.96 * std_r / np.sqrt(len(pos)))\n",
    "                else:\n",
    "                    peak_r_ci = np.nan\n",
    "            else:\n",
    "                w_mean = pos[0]\n",
    "                peak_r_ci = np.nan\n",
    "        else:\n",
    "            w_mean = peak_r\n",
    "            peak_r_ci = np.nan\n",
    "\n",
    "        peaks[inter] = {\"r\": w_mean, \"r_CI95\": peak_r_ci, \"g(r)\": peak_gr, \"g(r)_CI95\": peak_gr_ci}\n",
    "\n",
    "    # ---- optional Savitzky–Golay smoothing (for export convenience)\n",
    "    smoothed_df = None\n",
    "    if savgol_window and savgol_window > 2 and savgol_window % 2 == 1:\n",
    "        smoothed_df = pd.DataFrame({\"r (Å)\": r})\n",
    "        for inter in interaction_mapping:\n",
    "            y = weighted_gr[inter]\n",
    "            ci = result_df[f\"CI95 {inter}\"].to_numpy()\n",
    "            y_sm = savgol_filter(y, savgol_window, savgol_poly, mode=\"interp\")\n",
    "            ci_sm = savgol_filter(ci, savgol_window, savgol_poly, mode=\"interp\")\n",
    "            smoothed_df[f\"g(r) {inter}\"] = y_sm\n",
    "            smoothed_df[f\"CI95 {inter}\"] = ci_sm\n",
    "    elif savgol_window is not None:\n",
    "        msgs.append(\"[warn] savgol_window must be odd and >= 3; smoothing skipped\")\n",
    "\n",
    "    return GRAnalysisResult(\n",
    "        r=r,\n",
    "        weighted_gr_df=result_df,\n",
    "        smoothed_df=smoothed_df,\n",
    "        peaks=peaks,\n",
    "        weighted_gr=weighted_gr,\n",
    "        weighted_std=weighted_std,\n",
    "        used_experiments=used,\n",
    "        messages=msgs,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_weighted_gr_with_styler(\n",
    "    res: GRAnalysisResult,\n",
    "    sty: Optional[MDStyler] = None,\n",
    "    use_savgol: bool = True,\n",
    "    exclude_pairs: Iterable[str] = (\"AR-BR\", \"AR-BS\"),  # per your instruction\n",
    "    square: bool = False,\n",
    "    title: Optional[str] = None,\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plot weighted g(r) + 95% CI using your MDStyler.\n",
    "    AA solid vs CG dashed is not semantically meaningful here, so we use solid lines\n",
    "    with shaded CI; line dashes can be used to differentiate families if you wish.\n",
    "    \"\"\"\n",
    "    sty = sty or MDStyler().apply()\n",
    "    fig, ax = (sty.fig_square() if square else sty.fig_horizontal())\n",
    "\n",
    "    # choose which table to plot\n",
    "    df = res.smoothed_df if (use_savgol and res.smoothed_df is not None) else res.weighted_gr_df\n",
    "    r = res.r\n",
    "\n",
    "    # which interactions to draw (respect exclusion)\n",
    "    cols = [c for c in df.columns if c.startswith(\"g(r) \")]\n",
    "    inter_names = [c.replace(\"g(r) \", \"\") for c in cols]\n",
    "    draw = [(n, c) for n, c in zip(inter_names, cols) if n not in set(exclude_pairs)]\n",
    "\n",
    "    pal = sty.get_palette(len(draw))\n",
    "    for color, (name, col) in zip(pal, draw):\n",
    "        y = df[col].to_numpy()\n",
    "        # CI column key\n",
    "        ci_key = col.replace(\"g(r)\", \"CI95\")\n",
    "        ci = df[ci_key].to_numpy() if ci_key in df.columns else np.full_like(y, np.nan)\n",
    "\n",
    "        ax.plot(r, y, color=color, label=name)\n",
    "        # matte translucent band\n",
    "        ax.fill_between(r, y - ci, y + ci, color=color, alpha=0.18)\n",
    "\n",
    "    ax.set_xlabel(\"r (Å)\")\n",
    "    ax.set_ylabel(\"g(r)\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.legend(frameon=False, ncol=2)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] motor2m_frac3-0: column missing: g(r) 3-3\n",
      "[warn] motor2m_frac3-0: column missing: g(r) 4-4\n",
      "[warn] motor2m_squeeze10_frac-0: column missing: g(r) 3-3\n",
      "[warn] motor2m_squeeze10_frac-0: column missing: g(r) 4-4\n",
      "[warn] motor2m_squeeze12_frac-0_2: column missing: g(r) 3-3\n",
      "[warn] motor2m_squeeze12_frac-0_2: column missing: g(r) 4-4\n",
      "[warn] motor2m_squeeze12_frac-0_3: column missing: g(r) 3-3\n",
      "[warn] motor2m_squeeze12_frac-0_3: column missing: g(r) 4-4\n",
      "[warn] motor2m_squeeze14_frac-0_2: column missing: g(r) 3-3\n",
      "[warn] motor2m_squeeze14_frac-0_2: column missing: g(r) 4-4\n",
      "[warn] test_nr2: column missing: g(r) 3-3\n",
      "[warn] test_nr2: column missing: g(r) 4-4\n",
      "[warn] test_nr3: column missing: g(r) 3-3\n",
      "[warn] test_nr3: column missing: g(r) 4-4\n",
      "[warn] motor2m_frac3-0: column missing: g(r) 3-4\n",
      "[warn] motor2m_squeeze10_frac-0: column missing: g(r) 3-4\n",
      "[warn] motor2m_squeeze12_frac-0_2: column missing: g(r) 3-4\n",
      "[warn] motor2m_squeeze12_frac-0_3: column missing: g(r) 3-4\n",
      "[warn] motor2m_squeeze14_frac-0_2: column missing: g(r) 3-4\n",
      "[warn] test_nr2: column missing: g(r) 3-4\n",
      "[warn] test_nr3: column missing: g(r) 3-4\n"
     ]
    }
   ],
   "source": [
    "res = analyze_weighted_gr_styled(\n",
    "    experiment_ratios,\n",
    "    data_dir=\"../data\",\n",
    "    NMOLS=200,\n",
    "    r_range=(0.0, 20.0),\n",
    "    savgol_window=15,   # odd, >=3\n",
    "    savgol_poly=3,\n",
    ")\n",
    "for m in res.messages:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plot_weighted_gr_with_styler(\n",
    "    res,\n",
    "    sty=sty,\n",
    "    use_savgol=True,\n",
    "    exclude_pairs=(\"AR-BR\", \"AR-BS\"),   # your requirement\n",
    "    square=False,\n",
    "    title=None,\n",
    ")\n",
    "plt.title(\"AA\", fontsize=11, fontweight=\"bold\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical colormap for ratios\n",
    "RATIO_COLORS = {0: 'red', 10: 'purple', 90: 'blue'}\n",
    "\n",
    "def plot_parameter_vs_packing(all_df, parameter):\n",
    "    \"\"\"\n",
    "    Create scatter plot of a parameter vs packing with error bars, colored by ratio.\n",
    "    \n",
    "    Args:\n",
    "        all_df: DataFrame from concat_all\n",
    "        parameter: Parameter name to plot against packing\n",
    "    \"\"\"\n",
    "    if parameter not in all_df.columns or 'packing' not in all_df.columns:\n",
    "        print(f\"Missing required columns: {parameter} or packing\")\n",
    "        return\n",
    "    \n",
    "    # Check for CI columns\n",
    "    param_ci_col = f'CI-{parameter}'\n",
    "    packing_ci_col = 'CI-packing'\n",
    "    \n",
    "    if param_ci_col not in all_df.columns or packing_ci_col not in all_df.columns:\n",
    "        print(f\"Missing CI columns: {param_ci_col} or {packing_ci_col}\")\n",
    "        return\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Create scatter plot with different markers for molecule types\n",
    "    for molecule_type, marker in zip(['A', 'B'], ['o', 's']):\n",
    "        subset = all_df[all_df['molecule'] == molecule_type]\n",
    "\n",
    "        \n",
    "        # Create scatter with error bars\n",
    "        for _, row in subset.iterrows():\n",
    "            closest_ratio = min(RATIO_COLORS.keys(), key=lambda k: abs(k-row['ratioB']))\n",
    "            color = RATIO_COLORS[closest_ratio]\n",
    "            ax.errorbar(\n",
    "                row['packing'], row[parameter],\n",
    "                xerr=row[packing_ci_col], yerr=row[param_ci_col],\n",
    "                fmt=marker, markersize=8, \n",
    "                color=color,\n",
    "                alpha=0.7, elinewidth=0.5, capsize=0,\n",
    "                label=f\"Ratio {row['ratioB']:.0f}, Molecule {molecule_type}\"\n",
    "            )\n",
    "            \n",
    "    # Calculate and print statistics at the end of the function\n",
    "    print(f\"\\nStatistics for {parameter}:\")\n",
    "    for molecule in ['A', 'B']:\n",
    "        subset = all_df[all_df['molecule'] == molecule]\n",
    "        \n",
    "        # Calculate mean value\n",
    "        mean_val = subset[parameter].mean()\n",
    "        \n",
    "        # Properly account for both measurement uncertainty and data spread\n",
    "        n = len(subset)\n",
    "        if n > 1:\n",
    "            # Standard error of the mean from the spread of data points\n",
    "            std_error = subset[parameter].std(ddof=1) / np.sqrt(n)\n",
    "            \n",
    "            # Root mean square of individual confidence intervals\n",
    "            individual_ci_rms = np.sqrt(np.mean(subset[param_ci_col]**2))\n",
    "            \n",
    "            # Combined uncertainty using error propagation\n",
    "            combined_uncertainty = np.sqrt(std_error**2 + individual_ci_rms**2)\n",
    "            \n",
    "            # 95% confidence interval\n",
    "            ci_val = 1.96 * combined_uncertainty\n",
    "        else:\n",
    "            # If only one data point, use its confidence interval\n",
    "            ci_val = subset[param_ci_col].iloc[0]\n",
    "        \n",
    "        lower = mean_val - ci_val\n",
    "        upper = mean_val + ci_val\n",
    "        \n",
    "        # Calculate Pearson correlation with robust handling\n",
    "        # First, create a clean subset without any missing values\n",
    "        clean_subset = subset.dropna(subset=['packing', parameter])\n",
    "        \n",
    "        # Check data validity\n",
    "        x = clean_subset['packing'].values\n",
    "        y = clean_subset[parameter].values\n",
    "        \n",
    "        # Calculate correlation only if we have valid data\n",
    "        if len(x) >= 2:\n",
    "            # Check for variance in both variables\n",
    "            if np.var(x) > 0 and np.var(y) > 0:\n",
    "                pearson_r, p_value = scipy.stats.pearsonr(x, y)\n",
    "                correlation_str = f\"Pearson r = {pearson_r:.4f} (p = {p_value:.4f})\"\n",
    "            else:\n",
    "                correlation_str = \"No variance in data\"\n",
    "        else:\n",
    "            correlation_str = \"Insufficient data points\"\n",
    "        \n",
    "        print(f\"  Molecule {molecule}: {mean_val:.4f} [{lower:.4f}, {upper:.4f}], {correlation_str}\")\n",
    "        \n",
    "    # Add legend and labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))  # Keep only unique labels\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='best')\n",
    "    \n",
    "    ax.set_xlabel('Packing (motors/nm)')\n",
    "    ax.set_ylabel(parameter)\n",
    "    ax.set_title(f'{parameter} vs Packing')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_sasa_vs_inverse_packing(global_df):\n",
    "    \"\"\"\n",
    "    Create lineplot showing trajectory of sasa vs packing^-1 for all experiments.\n",
    "    \n",
    "    Args:\n",
    "        global_df: DataFrame from concat_global for sasa_new\n",
    "    \"\"\"\n",
    "    if 'sasa' not in global_df.columns or 'packing' not in global_df.columns:\n",
    "        print(\"Missing required columns: sasa_new or packing\")\n",
    "        return\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Get unique experiments\n",
    "    experiments = global_df['experiment'].unique()\n",
    "\n",
    "    # Plot each experiment\n",
    "    for exp in experiments:\n",
    "        subset = global_df[global_df['experiment'] == exp]\n",
    "        ratio = subset['ratioB'].iloc[0]  # Get ratio for this experiment\n",
    "        \n",
    "        # Sort by packing for a smooth line\n",
    "        #subset = subset.sort_values('packing')\n",
    "        closest_ratio = min(RATIO_COLORS.keys(), key=lambda k: abs(k-ratio))\n",
    "        color = RATIO_COLORS[closest_ratio]\n",
    "        \n",
    "        # Calculate inverse packing\n",
    "        inverse = 1 / subset['packing']\n",
    "        \n",
    "        ax.plot(inverse, subset['sasa'], \n",
    "                label=f\"RatioB {ratio:.0f}\",\n",
    "                color=color, linewidth=2, alpha=0.8)\n",
    "                \n",
    "        ax.plot(inverse.iloc[0], subset['sasa'].iloc[0], \n",
    "                marker='o', markersize=8, color=color)\n",
    "    \n",
    "    \n",
    "    # Add legend and labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='best')\n",
    "    ax.set_xlabel('Packing⁻¹ (nm/motor)')\n",
    "    ax.set_ylabel('SASA per molecule (nm$^2$)')\n",
    "    ax.set_title('SASA vs Inverse Packing')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_with_rolling_ci(global_df, param_name, window=10):\n",
    "    \"\"\"\n",
    "    Create lineplot of parameter vs time with rolling 95% CI.\n",
    "    \n",
    "    Args:\n",
    "        global_df: DataFrame from concat_global\n",
    "        param_name: Parameter name to plot (density or sasa_new)\n",
    "        window: Rolling window size (default: 10)\n",
    "    \"\"\"\n",
    "    if param_name not in global_df.columns or 'time' not in global_df.columns:\n",
    "        print(f\"Missing required columns: {param_name} or time\")\n",
    "        return\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Get unique experiments\n",
    "    experiments = global_df['experiment'].unique()\n",
    "\n",
    "    # Calculate confidence interval multiplier for 95% CI\n",
    "    ci_multiplier = 1.96\n",
    "    \n",
    "    # Plot each experiment\n",
    "    for exp in experiments:\n",
    "        subset = global_df[global_df['experiment'] == exp].copy()\n",
    "        ratio = subset['ratioB'].iloc[0]  # Get ratio for this experiment\n",
    "        \n",
    "        # Sort by time\n",
    "        subset = subset.sort_values('time')\n",
    "        closest_ratio = min(RATIO_COLORS.keys(), key=lambda k: abs(k-ratio))\n",
    "        color = RATIO_COLORS[closest_ratio]\n",
    "        \n",
    "        # Calculate rolling mean and standard deviation\n",
    "        subset[f'{param_name}_rolling'] = subset[param_name].rolling(window=window, center=True).mean()\n",
    "        subset[f'{param_name}_std'] = subset[param_name].rolling(window=window, center=True).std()\n",
    "        subset[f'{param_name}_n'] = subset[param_name].rolling(window=window, center=True).count()\n",
    "        \n",
    "        # Calculate confidence intervals\n",
    "        subset[f'{param_name}_ci'] = ci_multiplier * subset[f'{param_name}_std'] / np.sqrt(subset[f'{param_name}_n'])\n",
    "        \n",
    "        # Drop NA rows from rolling calculations\n",
    "        subset = subset.dropna(subset=[f'{param_name}_rolling', f'{param_name}_ci'])\n",
    "        \n",
    "        # Plot the line and confidence band\n",
    "        ax.plot(subset['time']/1000, subset[f'{param_name}_rolling'], \n",
    "                label=f\"Ratio {ratio:.0f}\",\n",
    "                color=color, linewidth=2)\n",
    "        \n",
    "        ax.fill_between(subset['time']/1000, \n",
    "                       subset[f'{param_name}_rolling'] - subset[f'{param_name}_ci'],\n",
    "                       subset[f'{param_name}_rolling'] + subset[f'{param_name}_ci'],\n",
    "                       color=color, alpha=0.2)\n",
    "    \n",
    "    # Add legend and labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='best')\n",
    "    ax.set_xlabel('Time (ns)')\n",
    "    ax.set_ylabel(param_name)\n",
    "    ax.set_title(f'{param_name} vs Time with 95% CI')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def calculate_density():\n",
    "    \"\"\"\n",
    "    Calculate density as packing / (pi*radius^2)\n",
    "    \n",
    "    Args:\n",
    "        global_df: DataFrame with packing and radius columns\n",
    "    \"\"\"\n",
    "    radius_global = concat_global('radius')\n",
    "    packing_global = concat_global('packing')\n",
    "    # Merge dataframes\n",
    "    density_df = pd.merge(\n",
    "        packing_global, radius_global[['time', 'experiment', 'radius']], \n",
    "        on=['time', 'experiment']\n",
    "    )\n",
    "    # Calculate density\n",
    "    density_df['density'] = density_df['packing'] / (np.pi * density_df['radius']**2)\n",
    "    \n",
    "    return density_df\n",
    "\n",
    "def plot_torsion_angles(data_path=Path('../data')):\n",
    "    \"\"\"\n",
    "    Create two scatter plots of torsion-theta vs torsion-phi for the last frame of each experiment.\n",
    "    Left plot: colored by ratio, Right plot: colored by molecule type (A: red, B: blue)\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to data directory\n",
    "    \"\"\"\n",
    "    # Collect data for all experiments\n",
    "    torsion_data = []\n",
    "    \n",
    "    for exp_name in valid_experiments:\n",
    "        # Get ratio for this experiment\n",
    "        ratio = get_experiment_ratio(exp_name, data_path)\n",
    "        if ratio is None:\n",
    "            continue\n",
    "            \n",
    "        # Load torsion-theta data\n",
    "        theta_file = data_path / f\"{exp_name}_torsion-theta.csv\"\n",
    "        if not theta_file.exists():\n",
    "            continue\n",
    "            \n",
    "        # Load torsion-phi data\n",
    "        phi_file = data_path / f\"{exp_name}_torsion-alpha.csv\"\n",
    "        if not phi_file.exists():\n",
    "            continue\n",
    "            \n",
    "        # Read the files\n",
    "        df_theta = pd.read_csv(theta_file)\n",
    "        df_phi = pd.read_csv(phi_file)\n",
    "        \n",
    "        # Check if they have the same structure\n",
    "        if df_theta.shape != df_phi.shape or 'resid' not in df_theta.columns or 'resid' not in df_phi.columns:\n",
    "            print(f\"Structure mismatch for {exp_name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Get the last column (last frame) for each file\n",
    "        last_theta_col = df_theta.columns[-1]\n",
    "        last_phi_col = df_phi.columns[-1]\n",
    "        \n",
    "        # Extract data for each molecule\n",
    "        for idx, row in df_theta.iterrows():\n",
    "            resid = row['resid']\n",
    "            \n",
    "            # Skip if this resid isn't in the phi data\n",
    "            if resid not in df_phi['resid'].values:\n",
    "                continue\n",
    "                \n",
    "            # Get theta and phi values\n",
    "            theta_val = row[last_theta_col]\n",
    "            phi_val = df_phi.iloc[idx,-1]\n",
    "            \n",
    "            # Mirror values for resid 2 and 4\n",
    "            if resid in [2, 3]: # The B-R isomer relaxes to A-S!!!\n",
    "                theta_val *= -1\n",
    "                phi_val *= -1\n",
    "            if theta_val > 100:\n",
    "                theta_val = theta_val - 360\n",
    "            if phi_val < -150:\n",
    "                phi_val += 360\n",
    "            \n",
    "            # Map resid to molecule type\n",
    "            molecule = 'A' if resid in [1, 2] else 'B'\n",
    "            \n",
    "            # Add to data collection\n",
    "            torsion_data.append({\n",
    "                'experiment': exp_name,\n",
    "                'resid': resid,\n",
    "                'molecule': molecule,\n",
    "                'ratioB': ratio,\n",
    "                'theta': theta_val,\n",
    "                'alpha': phi_val\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    torsion_df = pd.DataFrame(torsion_data)\n",
    "    \n",
    "    if torsion_df.empty:\n",
    "        print(\"No torsion data collected\")\n",
    "        return None\n",
    "        \n",
    "        # Create a single figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    # Plot colored by molecule type (previously on ax2)\n",
    "    molecule_colors = {'A': 'red', 'B': 'blue'}\n",
    "    for molecule_type, color in molecule_colors.items():\n",
    "        molecule_subset = torsion_df[torsion_df['molecule'] == molecule_type]\n",
    "        sc = ax.scatter(molecule_subset['theta'], molecule_subset['alpha'],\n",
    "                        color=color, marker='o', s=15, alpha=0.25,\n",
    "                        edgecolor='black', linewidth=0.2,\n",
    "                        label=f\"Molecule {molecule_type}\")\n",
    "\n",
    "    # Add KDE for each molecule type\n",
    "    for molecule_type, color in molecule_colors.items():\n",
    "        subset = torsion_df[torsion_df['molecule'] == molecule_type]\n",
    "        if len(subset) >= 10:  # Need sufficient points for KDE\n",
    "            try:\n",
    "                sns.kdeplot(x=subset['theta'], y=subset['alpha'],\n",
    "                            levels=5, linewidths=1, ax=ax,\n",
    "                            color=color, alpha=0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not create KDE for molecule {molecule_type}: {e}\")\n",
    "\n",
    "    # Add legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), title=\"Molecule Type\", loc='best')\n",
    "    ax.set_title('Torsion Angles by Molecule Type')\n",
    "\n",
    "    # Set labels and formatting\n",
    "    ax.set_xlabel(r'Torsion $\\theta$ (°)')\n",
    "    ax.set_ylabel(r'Torsion $\\alpha$ (°)')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Set limits\n",
    "    max_range = max(\n",
    "        abs(torsion_df['theta'].max()), abs(torsion_df['theta'].min()),\n",
    "        abs(torsion_df['alpha'].max()), abs(torsion_df['alpha'].min())\n",
    "    )\n",
    "\n",
    "    # Uncomment if you want specific limits\n",
    "    # ax.set_xlim(-280*1.1, 100*1.1)\n",
    "    # ax.set_ylim(-max_range*1.1, max_range*1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax, torsion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 25) (2412, 4) (2412, 4) (2412, 6)\n",
      "     time    packing       experiment  ratioB\n",
      "0     0.0  16.260718  motor2m_frac-10      10\n",
      "1  1000.0  16.695486  motor2m_frac-10      10\n",
      "2  2000.0  16.919118  motor2m_frac-10      10\n",
      "3  3000.0  16.977865  motor2m_frac-10      10\n",
      "4  4000.0  17.047296  motor2m_frac-10      10\n",
      "         experiment  ratioB molecule        RG     CI-RG    packing  \\\n",
      "0   motor2m_frac-10      10        A  8.603780  0.010997  17.297524   \n",
      "1   motor2m_frac-10      10        B  8.629517  0.033504  17.297524   \n",
      "2  motor2m_frac2-10      10        A  8.647189  0.009813  16.954748   \n",
      "3  motor2m_frac2-10      10        B  8.652479  0.040942  16.954748   \n",
      "4  motor2m_frac2-90      90        A  8.640262  0.027931  17.148262   \n",
      "\n",
      "   CI-packing      sasa   CI-sasa    torsion  ...  torsion-theta  \\\n",
      "0    0.011721  1.972909  0.003552   0.256950  ...    -105.395219   \n",
      "1    0.011721  1.972909  0.003552  14.949945  ...     -22.235020   \n",
      "2    0.009087  1.995068  0.003538        NaN  ...     -93.890053   \n",
      "3    0.009087  1.995068  0.003538        NaN  ...     -42.500173   \n",
      "4    0.008628  2.023674  0.003630        NaN  ...     -54.879500   \n",
      "\n",
      "   CI-torsion-theta  torsion-phi  CI-torsion-phi  voronota-volume  \\\n",
      "0          2.547358   -18.735419        0.159580       702.744158   \n",
      "1          2.295668    92.377439        7.374996       704.184172   \n",
      "2          2.753092   -20.165206        0.130661       700.334787   \n",
      "3          0.666347   151.382419        0.401886       713.096947   \n",
      "4          9.522542   -20.216945        0.469624       681.502105   \n",
      "\n",
      "   CI-voronota-volume  voronota-area  CI-voronota-area       g-r    CI-g-r  \n",
      "0            2.875588     353.767075          4.696800  0.928428  0.034848  \n",
      "1            9.454663     416.839271          6.375156  0.928428  0.034848  \n",
      "2            2.775477     359.284247          4.515909  0.962380  0.044039  \n",
      "3            9.989636     402.110552          7.100134  0.962380  0.044039  \n",
      "4            7.387436     448.217669          2.951440  0.205873  0.147565  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "all_df = concat_all()\n",
    "sasa_global = concat_global('sasa')\n",
    "packing_global = concat_global('packing')\n",
    "radius_global = concat_global('radius')\n",
    "density_df = calculate_density()\n",
    "print(all_df.shape, packing_global.shape, sasa_global.shape, density_df.shape)\n",
    "print(packing_global.head())\n",
    "print(all_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Intervals for density by ratioB:\n",
      "--------------------------------------------------\n",
      "ratioB = 0.00 (n=7):\n",
      "  Mean density: 0.7475\n",
      "  stdE density: 0.0024\n",
      "  95% CI: [0.7416, 0.7533]\n",
      "  CI width: 0.0117\n",
      "\n",
      "ratioB = 90.00 (n=5):\n",
      "  Mean density: 0.7396\n",
      "  stdE density: 0.0025\n",
      "  95% CI: [0.7326, 0.7465]\n",
      "  CI width: 0.0139\n",
      "\n",
      "95% Confidence Intervals for sasa by ratioB:\n",
      "--------------------------------------------------\n",
      "ratioB = 0.00 (n=7):\n",
      "  Mean sasa: 1.9525\n",
      "  stdE sasa: 0.0281\n",
      "  95% CI: [1.8836, 2.0213]\n",
      "  CI width: 0.1377\n",
      "\n",
      "ratioB = 90.00 (n=5):\n",
      "  Mean sasa: 1.9641\n",
      "  stdE sasa: 0.0177\n",
      "  95% CI: [1.9149, 2.0134]\n",
      "  CI width: 0.0985\n",
      "\n",
      "95% Confidence Intervals for radius by ratioB:\n",
      "--------------------------------------------------\n",
      "ratioB = 0.00 (n=7):\n",
      "  Mean radius: 2.7898\n",
      "  stdE radius: 0.0054\n",
      "  95% CI: [2.7766, 2.8031]\n",
      "  CI width: 0.0265\n",
      "\n",
      "ratioB = 90.00 (n=5):\n",
      "  Mean radius: 2.8201\n",
      "  stdE radius: 0.0057\n",
      "  95% CI: [2.8043, 2.8360]\n",
      "  CI width: 0.0317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_CI(global_df, parameter):\n",
    "    \"\"\"\n",
    "    Compute and print 95% confidence intervals for parameter means grouped by ratioB.\n",
    "    \n",
    "    Args:\n",
    "        global_df: DataFrame with columns: time, parameter, experiment, ratioB\n",
    "        parameter: Name of the parameter column to analyze\n",
    "    \"\"\"    \n",
    "    # Create a DataFrame to store results\n",
    "    results = []\n",
    "    # Process each experiment\n",
    "    for exp_name, exp_data in global_df.groupby('experiment'):\n",
    "        # Sort by time to ensure we get the last 10%\n",
    "        exp_data = exp_data.sort_values('time')\n",
    "        \n",
    "        # Calculate the index for the last 10% of the data\n",
    "        last_10_percent_idx = int(0.9 * len(exp_data))\n",
    "        \n",
    "        # Get the last 10% of the data\n",
    "        last_10_percent = exp_data.iloc[last_10_percent_idx:]\n",
    "        \n",
    "        # Compute average and std of the parameter in the last 10%\n",
    "        avg = last_10_percent[parameter].mean()\n",
    "        std = last_10_percent[parameter].std()\n",
    "        \n",
    "        # Get the ratioB value for this experiment\n",
    "        ratio_b = exp_data['ratioB'].iloc[0]\n",
    "        if ratio_b == 10:\n",
    "            ratio_b = 0\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'experiment': exp_name,\n",
    "            'ratioB': ratio_b,\n",
    "            'mean': avg,\n",
    "            'std': std\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Group by ratioB\n",
    "    grouped = results_df.groupby('ratioB')\n",
    "    \n",
    "    print(f\"95% Confidence Intervals for {parameter} by ratioB:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Calculate confidence intervals for each group\n",
    "    for ratio, group in grouped:\n",
    "        # Number of experiments in this group\n",
    "        n_experiments = len(group)\n",
    "        \n",
    "        # Calculate the weighted mean\n",
    "        weighted_mean = group['mean'].mean()\n",
    "        \n",
    "        # Propagate the standard error\n",
    "        # For independent measurements, standard error = sqrt(sum(std_i^2)) / N\n",
    "        propagated_std = np.sqrt(np.sum(group['std']**2) / n_experiments)\n",
    "        \n",
    "        # Calculate 95% confidence interval (using t-distribution for small samples)\n",
    "        t_value = stats.t.ppf(0.975, n_experiments - 1)  # 95% CI is +/- 1.96 for large samples\n",
    "        ci_lower = weighted_mean - t_value * propagated_std\n",
    "        ci_upper = weighted_mean + t_value * propagated_std\n",
    "        \n",
    "        print(f\"ratioB = {ratio:.2f} (n={n_experiments}):\")\n",
    "        print(f\"  Mean {parameter}: {weighted_mean:.4f}\")\n",
    "        print(f\"  stdE {parameter}: {propagated_std:.4f}\")\n",
    "        print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "        print(f\"  CI width: {ci_upper - ci_lower:.4f}\")\n",
    "        print()\n",
    "\n",
    "print_CI(density_df, 'density')\n",
    "print_CI(sasa_global, 'sasa')\n",
    "print_CI(radius_global, 'radius')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Intervals for RG by molecule type:\n",
      "--------------------------------------------------\n",
      "Molecule type: A (n=12):\n",
      "  Mean RG: 8.7261\n",
      "  95% CI: [8.7017, 8.7505]\n",
      "  stdE RG: 0.0111\n",
      "  CI width: 0.0488\n",
      "\n",
      "Molecule type: B (n=9):\n",
      "  Mean RG: 8.7821\n",
      "  95% CI: [8.7542, 8.8100]\n",
      "  stdE RG: 0.0121\n",
      "  CI width: 0.0558\n",
      "\n",
      "95% Confidence Intervals for voronota-volume by molecule type:\n",
      "--------------------------------------------------\n",
      "Molecule type: A (n=12):\n",
      "  Mean voronota-volume: 700.9644\n",
      "  95% CI: [694.1988, 707.7301]\n",
      "  stdE voronota-volume: 3.0739\n",
      "  CI width: 13.5314\n",
      "\n",
      "Molecule type: B (n=9):\n",
      "  Mean voronota-volume: 699.3775\n",
      "  95% CI: [691.7011, 707.0539]\n",
      "  stdE voronota-volume: 3.3289\n",
      "  CI width: 15.3529\n",
      "\n",
      "95% Confidence Intervals for voronota-area by molecule type:\n",
      "--------------------------------------------------\n",
      "Molecule type: A (n=12):\n",
      "  Mean voronota-area: 389.8923\n",
      "  95% CI: [385.3674, 394.4172]\n",
      "  stdE voronota-area: 2.0559\n",
      "  CI width: 9.0499\n",
      "\n",
      "Molecule type: B (n=9):\n",
      "  Mean voronota-area: 371.3587\n",
      "  95% CI: [364.6617, 378.0556]\n",
      "  stdE voronota-area: 2.9041\n",
      "  CI width: 13.3939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_molecule_CI(all_df, parameter):\n",
    "    \"\"\"\n",
    "    Compute and print 95% confidence intervals for parameter means grouped by molecule type.\n",
    "    \n",
    "    Args:\n",
    "        all_df: DataFrame generated by concat_all() with columns: experiment, ratioB, molecule, parameter, etc.\n",
    "        parameter: Name of the parameter column to analyze\n",
    "    \"\"\"\n",
    "   \n",
    "    # Check if parameter exists in the dataframe\n",
    "    if parameter not in all_df.columns:\n",
    "        print(f\"Error: '{parameter}' not found in the dataframe.\")\n",
    "        return\n",
    "    \n",
    "    # Check if CI column exists\n",
    "    ci_column = f'CI-{parameter}'\n",
    "    has_ci_column = ci_column in all_df.columns\n",
    "    \n",
    "    # Group by molecule\n",
    "    grouped = all_df.groupby('molecule')\n",
    "    \n",
    "    print(f\"95% Confidence Intervals for {parameter} by molecule type:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Calculate confidence intervals for each molecule type\n",
    "    for molecule_type, group in grouped:\n",
    "        # Remove NA values\n",
    "        valid_data = group[~group[parameter].isna()]\n",
    "        \n",
    "        if valid_data.empty:\n",
    "            print(f\"No valid data for molecule type {molecule_type}\")\n",
    "            continue\n",
    "            \n",
    "        # Count number of molecules of this type across all experiments\n",
    "        # Each row in the dataframe represents one molecule in one experiment\n",
    "        n_molecules = len(valid_data)\n",
    "        \n",
    "        # Calculate the mean across all molecules\n",
    "        weighted_mean = valid_data[parameter].mean()\n",
    "        \n",
    "        # If CI column exists, use it for propagation\n",
    "        if has_ci_column:\n",
    "            # Standard error from existing CIs\n",
    "            # CI = 1.96 * std / sqrt(n), so std = CI * sqrt(n) / 1.96\n",
    "            stds = valid_data[ci_column] * np.sqrt(1) / 1.96  # Each CI was for n=1\n",
    "            propagated_std = np.sqrt(np.sum(stds**2) / (n_molecules))\n",
    "        else:\n",
    "            # Use standard deviation directly\n",
    "            propagated_std = valid_data[parameter].std() / np.sqrt(n_molecules)\n",
    "        \n",
    "        # Calculate 95% confidence interval (using t-distribution for small samples)\n",
    "        t_value = stats.t.ppf(0.975, n_molecules - 1)\n",
    "        ci_lower = weighted_mean - t_value * propagated_std\n",
    "        ci_upper = weighted_mean + t_value * propagated_std\n",
    "        \n",
    "        print(f\"Molecule type: {molecule_type} (n={n_molecules}):\")\n",
    "        print(f\"  Mean {parameter}: {weighted_mean:.4f}\")\n",
    "        print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "        print(f\"  stdE {parameter}: {propagated_std:.4f}\")\n",
    "        print(f\"  CI width: {ci_upper - ci_lower:.4f}\")\n",
    "        print()\n",
    "print_molecule_CI(all_df, 'RG')\n",
    "print_molecule_CI(all_df, 'voronota-volume')\n",
    "print_molecule_CI(all_df, 'voronota-area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create density vs time plot\n",
    "print(\"Creating density vs time plot...\")\n",
    "fig1, _ = plot_with_rolling_ci(density_df, 'density')\n",
    "plt.ylabel('Density (motors/nm$^3$)')\n",
    "fig1.savefig('../figs/density_vs_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Creating packing vs time plot...\")\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "color='blue'\n",
    "window=5\n",
    "experiments = density_df['experiment'].unique()\n",
    "param_name='packing'\n",
    "\n",
    "for exp in experiments:\n",
    "    subset = density_df[density_df['experiment'] == exp].copy()\n",
    "    subset = subset.sort_values('time')\n",
    "    subset[f'{param_name}_rolling'] = subset[param_name].rolling(window=window, center=True).mean()\n",
    "    subset = subset.dropna(subset=[f'{param_name}_rolling'])\n",
    "    ax.plot(subset['time']/1000, subset[f'{param_name}_rolling'],\n",
    "            color=color, linewidth=2)\n",
    "ax.set_xlabel('Time (ns)')\n",
    "ax.set_ylabel('Packing (motors/nm)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figs/packing_vs_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create SASA vs time plot\n",
    "print(\"Creating SASA vs time plot...\")\n",
    "fig2, _ = plot_with_rolling_ci(sasa_global, 'sasa')\n",
    "plt.ylabel('SASA (nm$^2$/motor)')\n",
    "fig2.savefig('../figs/sasa_vs_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create SASA vs inverse packing plot\n",
    "print(\"Creating SASA vs inverse packing plot...\")\n",
    "fig3, _ = plot_sasa_vs_inverse_packing(pd.merge(\n",
    "    sasa_global, packing_global[['time', 'experiment', 'packing']], \n",
    "    on=['time', 'experiment']\n",
    "))\n",
    "fig3.savefig('../figs/sasa_vs_inverse_packing.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['CI-ratioB'] = all_df['ratioB'] * 0\n",
    "parameters = [col for col in all_df.columns if col not in \n",
    "                     ['experiment', 'ratio', 'molecule', 'g-r', 'packing', 'torsion', 'torsion-theta', 'torsion-phi'] \n",
    "                     and not col.startswith('CI-')]\n",
    "        \n",
    "for param in parameters:\n",
    "    print(f\"Creating {param} vs packing plot...\")\n",
    "    try:\n",
    "        fig, _ = plot_parameter_vs_packing(all_df, param)\n",
    "        fig.savefig(f'../figs/{param}_vs_packing.png', dpi=300, bbox_inches='tight')\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating plot for {param}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU\n",
      "            experiment  resid molecule  ratioB       theta      alpha\n",
      "466   motor2m_frac2-90    4.0        B      90 -163.621834  60.270402\n",
      "566   motor2m_frac2-90    4.0        B      90 -182.321937  52.377337\n",
      "1166  motor2m_frac3-90    4.0        B      90 -165.929586  60.808019\n",
      "1266  motor2m_frac4-90    4.0        B      90 -181.523579  51.490146\n",
      "Center upper\n",
      "                     experiment  resid molecule  ratioB      theta       alpha\n",
      "1233           motor2m_frac4-90    3.0        B      90 -66.126522  107.870764\n",
      "1333           motor2m_frac4-90    3.0        B      90 -52.192386  138.810043\n",
      "1352           motor2m_frac4-90    3.0        B      90 -64.455858  116.034166\n",
      "1378           motor2m_frac4-90    4.0        B      90 -64.013042  127.952670\n",
      "2183  motor2m_squeeze10_frac-90    4.0        B      90 -63.170582  112.542388\n",
      "Center lower\n",
      "            experiment  resid molecule  ratioB      theta      alpha\n",
      "93     motor2m_frac-10    3.0        B      10 -45.694376  81.699121\n",
      "193    motor2m_frac-10    3.0        B      10 -50.205168  73.356964\n",
      "432   motor2m_frac2-90    3.0        B      90 -44.390984  88.735815\n",
      "452   motor2m_frac2-90    3.0        B      90 -46.031758  83.030956\n",
      "532   motor2m_frac2-90    3.0        B      90 -52.032221  76.415312\n",
      "552   motor2m_frac2-90    3.0        B      90 -53.952116  74.985057\n",
      "1052  motor2m_frac3-90    3.0        B      90 -41.890425  84.273804\n",
      "1066  motor2m_frac3-90    4.0        B      90 -57.903188  76.297459\n",
      "1152  motor2m_frac3-90    3.0        B      90 -47.135130  88.241941\n",
      "1366  motor2m_frac4-90    4.0        B      90 -43.149369  83.535024\n"
     ]
    }
   ],
   "source": [
    "print('AU')\n",
    "print(df[(df.molecule == 'B') & (df.theta < -100)].head())\n",
    "print('Center upper')\n",
    "print(df[(df.molecule == 'B') & (df.theta < -10) & (df.theta > -100) & (df.alpha > 100)])\n",
    "print('Center lower')\n",
    "print(df[(df.molecule == 'B') & (df.theta < -10) & (df.theta > -100) & (df.alpha < 100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_weighted_gr(experiment_ratios, r_range=None, rolling_window=None):\n",
    "    \"\"\"\n",
    "    Analyze g(r) data across multiple experiments with weighted averaging.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_ratios : dict\n",
    "        Dictionary with experiment names as keys and molecule ratios as values\n",
    "    r_range : tuple, optional\n",
    "        (min_r, max_r) to filter data range for plotting and analysis\n",
    "    rolling_window : int, optional\n",
    "        Window size for rolling average smoothing in plots. If None, no smoothing is applied.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing DataFrames with processed data and peak information\n",
    "    \"\"\"\n",
    "    # Dictionary to store dataframes from each experiment\n",
    "    experiment_data = {}\n",
    "    \n",
    "    # Dictionary to store molecule counts for each experiment\n",
    "    molecule_counts = {}\n",
    "    \n",
    "    # Read data for each experiment\n",
    "    for experiment_name, ratio in experiment_ratios.items():\n",
    "        # Calculate molecule counts\n",
    "        N_1 = N_2 = int((100-ratio)/100 * NMOLS/2)\n",
    "        N_3 = N_4 = int(ratio/100 * NMOLS/2)\n",
    "        \n",
    "        molecule_counts[experiment_name] = {\n",
    "            1: N_1,\n",
    "            2: N_2,\n",
    "            3: N_3,\n",
    "            4: N_4\n",
    "        }\n",
    "        \n",
    "        # Read CSV data\n",
    "        file_path = f'../data/{experiment_name}_g-r.csv'\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Warning: File not found: {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        df = pd.read_csv(file_path)\n",
    "        experiment_data[experiment_name] = df\n",
    "    \n",
    "    if not experiment_data:\n",
    "        raise ValueError(\"No valid data files found\")\n",
    "    \n",
    "    # Get r values from the first dataframe\n",
    "    r_values = experiment_data[list(experiment_data.keys())[0]]['r (Å)'].values\n",
    "    \n",
    "    # Apply r_range filter if provided\n",
    "    if r_range:\n",
    "        min_r, max_r = r_range\n",
    "        r_mask = (r_values >= min_r) & (r_values <= max_r)\n",
    "        r_values = r_values[r_mask]\n",
    "    else:\n",
    "        r_mask = slice(None)  # No masking\n",
    "    \n",
    "    # Initialize dictionaries for results\n",
    "    weighted_gr = {}\n",
    "    weighted_std = {}\n",
    "    weights_sum = {}\n",
    "    \n",
    "\n",
    "    # Dictionary for mapping interaction pairs\n",
    "    interaction_mapping = {\n",
    "        'A-A': ['g(r) 1-1', 'g(r) 2-2'],\n",
    "        'AR-AS': ['g(r) 1-2'],\n",
    "        'A-B': ['g(r) 1-3', 'g(r) 2-4'],\n",
    "        'AR-BS': ['g(r) 1-4', 'g(r) 2-3'],\n",
    "        'B-B': ['g(r) 3-3', 'g(r) 4-4'],\n",
    "        'BR-BS': ['g(r) 3-4']\n",
    "    }    # Dictionary to track peak positions across datasets\n",
    "    peak_positions = {interaction_name: [] for interaction_name in interaction_mapping.keys()}\n",
    "    \n",
    "    \n",
    "    # Process each type of interaction\n",
    "    for interaction_name, column_keys in interaction_mapping.items():\n",
    "        weighted_gr[interaction_name] = np.zeros_like(r_values)\n",
    "        weights_sum[interaction_name] = 0\n",
    "        \n",
    "        # Store values from all experiments for standard deviation calculation\n",
    "        all_values = []\n",
    "        all_weights = []\n",
    "        \n",
    "        # Process each experiment\n",
    "        for experiment_name, df in experiment_data.items():\n",
    "            weights = []\n",
    "            values_list = []\n",
    "            \n",
    "            # Process each column for this interaction type\n",
    "            for col_key in column_keys:\n",
    "                # Extract resids from the column name\n",
    "                parts = col_key.split()[-1].split('-')\n",
    "                resid_i, resid_j = int(parts[0]), int(parts[1])\n",
    "                \n",
    "                # Get molecule counts\n",
    "                N_i = molecule_counts[experiment_name][resid_i]\n",
    "                N_j = molecule_counts[experiment_name][resid_j]\n",
    "                \n",
    "                # Calculate weight based on number of possible interactions\n",
    "                if resid_i == resid_j:\n",
    "                    # For same type interactions (e.g., 1-1)\n",
    "                    weight = N_i * (N_i - 1)\n",
    "                else:\n",
    "                    # For different type interactions\n",
    "                    weight = N_i * N_j\n",
    "                \n",
    "                # Skip if column doesn't exist\n",
    "                if col_key not in df.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Apply r_range filter if provided\n",
    "                values = df[col_key].values[r_mask]\n",
    "                \n",
    "                # Store for this specific column\n",
    "                values_list.append(values)\n",
    "                weights.append(weight)\n",
    "            \n",
    "            # If we have values for this experiment and interaction\n",
    "            if values_list:\n",
    "                # Average across symmetric columns first (within this experiment)\n",
    "                exp_avg_values = np.zeros_like(r_values)\n",
    "                total_weight = sum(weights)\n",
    "                for val, w in zip(values_list, weights):\n",
    "                    exp_avg_values += val * (w / total_weight)\n",
    "                \n",
    "                # Store for cross-experiment calculations\n",
    "                all_values.append(exp_avg_values)\n",
    "                all_weights.append(total_weight)\n",
    "                \n",
    "                # Find peak position for this experiment and interaction\n",
    "                peak_idx = np.argmax(exp_avg_values)\n",
    "                peak_r = r_values[peak_idx]\n",
    "                peak_positions[interaction_name].append((peak_r, total_weight))\n",
    "                \n",
    "                # Update global weighted sum\n",
    "                weighted_gr[interaction_name] += exp_avg_values * total_weight\n",
    "                weights_sum[interaction_name] += total_weight\n",
    "        \n",
    "        # Calculate weighted average across experiments\n",
    "        if weights_sum[interaction_name] > 0:\n",
    "            weighted_gr[interaction_name] /= weights_sum[interaction_name]\n",
    "            \n",
    "            # Calculate weighted standard deviation\n",
    "            all_values = np.array(all_values)\n",
    "            all_weights = np.array(all_weights)\n",
    "            \n",
    "            # Weighted sample variance calculation\n",
    "            diff_squared = np.zeros_like(r_values)\n",
    "            for vals, weight in zip(all_values, all_weights):\n",
    "                diff_squared += weight * (vals - weighted_gr[interaction_name])**2\n",
    "            \n",
    "            # Bessel's correction for weighted std (for sample rather than population)\n",
    "            correction = 1 - np.sum(all_weights**2) / (np.sum(all_weights)**2)\n",
    "            weighted_var = diff_squared / (np.sum(all_weights) * correction)\n",
    "            weighted_std[interaction_name] = np.sqrt(weighted_var)\n",
    "    \n",
    "    # Create result dataframe with r values and weighted g(r) for each interaction\n",
    "    result_df = pd.DataFrame({'r (Å)': r_values})\n",
    "    \n",
    "    # Add weighted g(r) and 95% CI to dataframe\n",
    "    n_experiments = len(experiment_data)\n",
    "    for interaction_name in interaction_mapping.keys():\n",
    "        result_df[f'g(r) {interaction_name}'] = weighted_gr[interaction_name]\n",
    "        ci_95 = 1.96 * weighted_std[interaction_name] / np.sqrt(n_experiments)\n",
    "        result_df[f'CI95 {interaction_name}'] = ci_95\n",
    "    \n",
    "    # Find peaks in g(r) for each interaction\n",
    "    peaks_info = {}\n",
    "    for interaction_name in interaction_mapping.keys():\n",
    "        gr_values = weighted_gr[interaction_name]\n",
    "        # Simple peak detection - find maximum in weighted average\n",
    "        peak_idx = np.argmax(gr_values)\n",
    "        peak_r = r_values[peak_idx]\n",
    "        peak_gr = gr_values[peak_idx]\n",
    "        peak_gr_ci = 1.96 * weighted_std[interaction_name][peak_idx] / np.sqrt(n_experiments)\n",
    "        \n",
    "        # Calculate statistics for peak positions across datasets\n",
    "        if peak_positions[interaction_name]:\n",
    "            # Extract r values and weights\n",
    "            positions, weights = zip(*peak_positions[interaction_name])\n",
    "            positions = np.array(positions)\n",
    "            weights = np.array(weights)\n",
    "            \n",
    "            # Calculate weighted mean of peak positions\n",
    "            weighted_peak_r = np.sum(positions * weights) / np.sum(weights)\n",
    "            \n",
    "            # Calculate weighted standard deviation of peak positions\n",
    "            diff_squared = np.sum(weights * (positions - weighted_peak_r)**2)\n",
    "            correction = 1 - np.sum(weights**2) / (np.sum(weights)**2)\n",
    "            weighted_var = diff_squared / (np.sum(weights) * correction)\n",
    "            weighted_std_r = np.sqrt(weighted_var)\n",
    "            \n",
    "            # Calculate 95% CI for peak position\n",
    "            peak_r_ci = 1.96 * weighted_std_r / np.sqrt(len(positions))\n",
    "        else:\n",
    "            weighted_peak_r = peak_r\n",
    "            peak_r_ci = 0\n",
    "        \n",
    "        peaks_info[interaction_name] = {\n",
    "            'r': weighted_peak_r,\n",
    "            'r_CI95': peak_r_ci,\n",
    "            'g(r)': peak_gr,\n",
    "            'g(r)_CI95': peak_gr_ci\n",
    "        }\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    \n",
    "    for i, (interaction_name, color) in enumerate(zip(interaction_mapping.keys(), colors)):\n",
    "        gr_values = weighted_gr[interaction_name]\n",
    "        ci_values = 1.96 * weighted_std[interaction_name] / np.sqrt(n_experiments)\n",
    "        \n",
    "        # Apply rolling average if specified\n",
    "        if rolling_window and rolling_window > 1:\n",
    "            # Calculate rolling average for smoother plotting\n",
    "            pd_series = pd.Series(gr_values)\n",
    "            smoothed_gr = pd_series.rolling(window=rolling_window, center=True).mean()\n",
    "            \n",
    "            # Handle NaN values at the edges due to rolling window\n",
    "            # Use original values at the edges\n",
    "            edge_points = rolling_window // 2\n",
    "            smoothed_gr[:edge_points] = gr_values[:edge_points]\n",
    "            smoothed_gr[-edge_points:] = gr_values[-edge_points:]\n",
    "            \n",
    "            # Also smooth the confidence intervals\n",
    "            pd_ci = pd.Series(ci_values)\n",
    "            smoothed_ci = pd_ci.rolling(window=rolling_window, center=True).mean()\n",
    "            smoothed_ci[:edge_points] = ci_values[:edge_points]\n",
    "            smoothed_ci[-edge_points:] = ci_values[-edge_points:]\n",
    "            \n",
    "            # Plot both original (transparent) and smoothed data\n",
    "            plt.plot(r_values, gr_values, color=color, alpha=0.2)\n",
    "            plt.plot(r_values, smoothed_gr, label=f'{interaction_name} (smoothed)', color=color)\n",
    "            plt.fill_between(r_values, \n",
    "                            smoothed_gr - smoothed_ci, \n",
    "                            smoothed_gr + smoothed_ci, \n",
    "                            color=color, alpha=0.2)\n",
    "        else:\n",
    "            # Plot original data without smoothing\n",
    "            plt.plot(r_values, gr_values, label=f'{interaction_name}', color=color)\n",
    "            plt.fill_between(r_values, \n",
    "                            gr_values - ci_values, \n",
    "                            gr_values + ci_values, \n",
    "                            color=color, alpha=0.2)\n",
    "    \n",
    "    plt.xlabel('r (Å)')\n",
    "    plt.ylabel('g(r)')\n",
    "    title = 'Weighted Average Radial Distribution Functions with 95% CI'\n",
    "    if rolling_window and rolling_window > 1:\n",
    "        title += f' (Smoothed with {rolling_window}-point rolling average)'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print peak information\n",
    "    print(\"First peaks in g(r) for each interaction:\")\n",
    "    for interaction_name, peak_data in peaks_info.items():\n",
    "        g_lower = peak_data['g(r)'] - peak_data['g(r)_CI95']\n",
    "        g_upper = peak_data['g(r)'] + peak_data['g(r)_CI95']\n",
    "        r_lower = peak_data['r'] - peak_data['r_CI95'] \n",
    "        r_upper = peak_data['r'] + peak_data['r_CI95']\n",
    "        print(f\"{interaction_name}: g(r) = {peak_data['g(r)']:.4f} [{g_lower:.4f}, {g_upper:.4f}] at r = {peak_data['r']:.4f} [{r_lower:.4f}, {r_upper:.4f}] Å\")\n",
    "    \n",
    "    \n",
    "    # Create separate smoothed dataframe if rolling average was applied\n",
    "    smoothed_df = None\n",
    "    if rolling_window and rolling_window > 1:\n",
    "        smoothed_df = pd.DataFrame({'r (Å)': r_values})\n",
    "        \n",
    "        for interaction_name in interaction_mapping.keys():\n",
    "            # Apply rolling mean to g(r) values\n",
    "            pd_series = pd.Series(weighted_gr[interaction_name])\n",
    "            smoothed_gr = pd_series.rolling(window=rolling_window, center=True).mean()\n",
    "            \n",
    "            # Handle NaN values at the edges\n",
    "            edge_points = rolling_window // 2\n",
    "            smoothed_gr[:edge_points] = weighted_gr[interaction_name][:edge_points]\n",
    "            smoothed_gr[-edge_points:] = weighted_gr[interaction_name][-edge_points:]\n",
    "            \n",
    "            # Also smooth the confidence intervals\n",
    "            ci_values = 1.96 * weighted_std[interaction_name] / np.sqrt(n_experiments)\n",
    "            pd_ci = pd.Series(ci_values)\n",
    "            smoothed_ci = pd_ci.rolling(window=rolling_window, center=True).mean()\n",
    "            smoothed_ci[:edge_points] = ci_values[:edge_points]\n",
    "            smoothed_ci[-edge_points:] = ci_values[-edge_points:]\n",
    "            \n",
    "            # Add to dataframe\n",
    "            smoothed_df[f'g(r) {interaction_name} (smoothed)'] = smoothed_gr\n",
    "            smoothed_df[f'CI95 {interaction_name} (smoothed)'] = smoothed_ci\n",
    "    \n",
    "    return {\n",
    "        'weighted_gr_df': result_df,\n",
    "        'smoothed_df': smoothed_df,\n",
    "        'peaks': peaks_info,\n",
    "        'r_values': r_values,\n",
    "        'weighted_gr': weighted_gr,\n",
    "        'weighted_std': weighted_std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = analyze_weighted_gr(experiment_ratios,rolling_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.constants as constant\n",
    "import scipy.special as special\n",
    "\n",
    "\n",
    "def cylindrical_PB_potential(r, debye_length, radius, surface_charge_density, epsilon_r=78.5):\n",
    "    \"\"\"\n",
    "    Calculate the electrostatic potential at distance r from the cylinder axis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    r : float\n",
    "        Distance from the cylinder axis (in meters)\n",
    "    debye_length : float\n",
    "        Debye screening length (in meters)\n",
    "    radius : float\n",
    "        Radius of the cylinder (in meters)\n",
    "    surface_charge_density : float\n",
    "        Surface charge density (in C/m²)\n",
    "    epsilon_r : float\n",
    "        Relative permittivity of the medium (default: water at 25°C)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Potential in Volts\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    epsilon_0 = constant.epsilon_0  # Vacuum permittivity (F/m)\n",
    "    \n",
    "    # Check if r is outside the cylinder\n",
    "    if r < radius:\n",
    "        raise ValueError(\"r must be greater than or equal to the cylinder radius\")\n",
    "    \n",
    "    # Calculate the potential\n",
    "    prefactor = surface_charge_density * radius / (epsilon_r * epsilon_0)\n",
    "    bessel_ratio = special.k0(r / debye_length) / special.k1(radius / debye_length)\n",
    "    potential = prefactor * bessel_ratio\n",
    "    \n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 20*1e-9\n",
    "radius = 2.5*1e-9         # Cylinder radius (1 nm)\n",
    "r = x/2             # Distance from cylinder axis (5 nm)\n",
    "dz = 0.05e-9\n",
    "debye_length = 3.044/(1/constant.N_A/dz)**0.5*x*1e-10     # Debye length (1 nm)\n",
    "print(f'Debey: {debye_length*1e9:.2f} nm')\n",
    "surface_charge = -2*constant.e/(radius*dz*2*constant.pi)   # Surface charge density (0.05 C/m²)\n",
    "print(f'Sigma: {surface_charge:.2f} C/m2')\n",
    "\n",
    "# Calculate potential at distance r\n",
    "potential = cylindrical_PB_potential(r, debye_length, radius, surface_charge)\n",
    "print(f\"Potential at {(r-radius)*1e9:.2f} nm from surface: {potential:.4f} V\")\n",
    "\n",
    "# Calculate potential at different distances\n",
    "distances = np.linspace(radius, radius + 10e-9, 100)\n",
    "potentials = [cylindrical_PB_potential(d, debye_length, radius, surface_charge) for d in distances]\n",
    "plt.plot(distances, potentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molecular-motor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
